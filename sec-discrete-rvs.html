<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US" dir="ltr">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Discrete random variables</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="Math 487 at UNL">
<meta property="book:author" content="Zach Norwood">
<script>
var runestoneMathReady = new Promise((resolve) => window.rsMathReady = resolve);
window.MathJax = {
  "tex": {
    "inlineMath": [
      [
        "\\(",
        "\\)"
      ]
    ],
    "tags": "none",
    "tagSide": "right",
    "tagIndent": ".8em",
    "packages": {
      "[+]": [
        "base",
        "extpfeil",
        "ams",
        "amscd",
        "color",
        "newcommand",
        "knowl"
      ]
    }
  },
  "options": {
    "ignoreHtmlClass": "tex2jax_ignore|ignore-math",
    "processHtmlClass": "process-math"
  },
  "chtml": {
    "scale": 0.98,
    "mtextInheritFont": true
  },
  "loader": {
    "load": [
      "input/asciimath",
      "[tex]/extpfeil",
      "[tex]/amscd",
      "[tex]/color",
      "[tex]/newcommand",
      "[pretext]/mathjaxknowl3.js"
    ],
    "paths": {
      "pretext": "https://pretextbook.org/js/lib"
    }
  },
  "startup": {
    pageReady() {
      return MathJax.startup.defaultPageReady().then(function () {
      console.log("in ready function");
      rsMathReady();
      }
    )}
  }
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js" integrity="sha512-4xUl/d6D6THrAnXAwGajXkoWaeMNwEKK4iNfq5DotEbLPAfk6FSxSP3ydNxqDgCw1c/0Z1Jg6L8h2j+++9BZmg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="lunr-pretext-search-index.js" async=""></script><script src="https://pretextbook.org/js/0.3/pretext_search.js"></script><link href="https://pretextbook.org/css/0.8/pretext_search.css" rel="stylesheet" type="text/css">
<script>js_version = 0.3</script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.3/pretext.js"></script><script>miniversion=0.1</script><script src="https://pretextbook.org/js/0.3/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/0.3/user_preferences.js"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&amp;family=Noto+Serif:ital,wght@0,400;0,700;1,400;1,700&amp;family=Tinos:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" rel="stylesheet">
<link href="https://fonts.cdnfonts.com/css/dejavu-serif" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Roboto+Serif:opsz,wdth,wght@8..144,50..150,100..900&amp;display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Open+Sans:wdth,wght@75..100,300..800&amp;display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200">
<link href="https://pretextbook.org/css/0.8/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.8/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.8/shell_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.8/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.8/navbar_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.8/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.8/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.8/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.8/colors_blue_red.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.8/setcolors.css" rel="stylesheet" type="text/css">
</head>
<body class="pretext book ignore-math">
<a class="assistive" href="#ptx-content">Skip to main content</a><header id="ptx-masthead" class="ptx-masthead"><div class="ptx-banner">
<a id="logo-link" class="logo-link" href="" target="_blank"><img src="external/dice.png" alt="Logo image"></a><div class="title-container">
<h1 class="heading"><a href="math-487-notes.html"><span class="title">Math 487 at UNL:</span> <span class="subtitle">Fall 2023 lecture notes</span></a></h1>
<p class="byline">Zach Norwood</p>
</div>
<div id="searchresultsplaceholder" class="searchresultsplaceholder" style="display: none">
<button id="closesearchresults" class="closesearchresults" onclick="document.getElementById('searchresultsplaceholder').style.display = 'none'; return false;">x</button><h2>Search Results: <span id="searchterms" class="searchterms"></span>
</h2>
<div id="searchempty" class="searchempty"><span>No results.</span></div>
<ol id="searchresults" class="searchresults"></ol>
</div>
</div></header><nav id="ptx-navbar" class="ptx-navbar navbar"><button class="toc-toggle button" title="Contents"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5d2;</span><span class="name">Contents</span></button><span class="nav-other-controls"></span><span class="treebuttons"><a class="previous-button button" href="sec-random-variables-theory.html" title="Previous"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cb;</span><span class="name">Prev</span></a><a class="up-button button" href="ch-random-variables.html" title="Up"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5ce;</span><span class="name">Up</span></a><a class="next-button button" href="sec-cts-rvs.html" title="Next"><span class="name">Next</span><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cc;</span></a></span><div class="searchbox"><div class="searchwidget">
<input id="ptxsearch" class="ptxsearch" type="text" name="terms" placeholder="Search" onchange="doSearch()"><button id="searchbutton" class="searchbutton" type="button" onclick="doSearch()" title="Search book"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe8b6;</span><span class="name">Search Book</span></button>
</div></div>
<span class="nav-runestone-controls"><button id="user-preferences-button" class="user-preferences-button button" title="Modify user preferences"><span id="avatarbutton" class="avatarbutton name">You!</span><div id="preferences_menu_holder" class="preferences_menu_holder hidden"><ol id="preferences_menu" class="preferences_menu" style="font-family: 'Roboto Serif', serif;">
<li data-env="avatar" tabindex="-1">Choose avatar<div class="wrap_to_submenu"><span class="to_submenu">▻</span></div>
<ol class="hidden avatar">
<li data-val="You!" tabindex="-1">
<span id="theYou!" class="avatarcheck">✔️</span>You!</li>
<li data-val="😺" tabindex="-1">
<span id="the😺" class="avatarcheck"></span>😺</li>
<li data-val="👤" tabindex="-1">
<span id="the👤" class="avatarcheck"></span>👤</li>
<li data-val="👽" tabindex="-1">
<span id="the👽" class="avatarcheck"></span>👽</li>
<li data-val="🐶" tabindex="-1">
<span id="the🐶" class="avatarcheck"></span>🐶</li>
<li data-val="🐼" tabindex="-1">
<span id="the🐼" class="avatarcheck"></span>🐼</li>
<li data-val="🌈" tabindex="-1">
<span id="the🌈" class="avatarcheck"></span>🌈</li>
</ol>
</li>
<li data-env="fontfamily" tabindex="-1">Font family<div class="wrap_to_submenu"><span class="to_submenu">▻</span></div>
<ol class="hidden fontfamily">
<li data-val="face" data-change="OS" tabindex="-1" style="font-family: 'Open Sans'">
<span id="theOS" class="ffcheck">✔️</span><span class="name">Open Sans</span><span class="sample">AaBbCc 123 PreTeXt</span>
</li>
<li data-val="face" data-change="RS" tabindex="-1" style="font-family: 'Roboto Serif'">
<span id="theRS" class="ffcheck"></span><span class="name">Roboto Serif</span><span class="sample">AaBbCc 123 PreTeXt</span>
</li>
</ol>
</li>
<li data-env="font" tabindex="-1">Adjust font<div class="wrap_to_submenu"><span class="to_submenu">▻</span></div>
<ol class="hidden fonts">
<li>Size</li>
<li><span id="thesize">12</span></li>
<li data-val="size" data-change="-1" tabindex="-1" style="font-size: 80%">Smaller</li>
<li data-val="size" data-change="1" tabindex="-1" style="font-size: 110%">Larger</li>
<li>Width</li>
<li><span id="thewdth">100</span></li>
<li data-val="wdth" data-change="-5" tabindex="-1" style="font-variation-settings: 'wdth' 60">narrower</li>
<li data-val="wdth" data-change="5" tabindex="-1" style="font-variation-settings: 'wdth' 150">wider</li>
<li>Weight</li>
<li><span id="thewght">400</span></li>
<li data-val="wght" data-change="-50" tabindex="-1" style="font-weight: 200">thinner</li>
<li data-val="wght" data-change="50" tabindex="-1" style="font-weight: 700">heavier</li>
<li>Letter spacing</li>
<li>
<span id="thelspace">0</span><span class="byunits">/200</span>
</li>
<li data-val="lspace" data-change="-1" tabindex="-1">closer</li>
<li data-val="lspace" data-change="1" tabindex="-1">f a r t h e r</li>
<li>Word spacing</li>
<li>
<span id="thewspace">0</span><span class="byunits">/50</span>
</li>
<li data-val="wspace" data-change="-1" tabindex="-1">smaller gap </li>
<li data-val="wspace" data-change="1" tabindex="-1">larger gap</li>
<li>Line Spacing</li>
<li>
<span id="theheight">135</span><span class="byunits">/100</span>
</li>
<li data-val="height" data-change="-5" tabindex="-1" style="line-height: 1">closer<br>together</li>
<li data-val="height" data-change="5" tabindex="-1" style="line-height: 1.75">further<br>apart</li>
</ol>
</li>
<li data-env="atmosphere" tabindex="-1">Light/dark mode<div class="wrap_to_submenu"><span class="to_submenu">▻</span></div>
<ol class="hidden atmosphere">
<li data-val="default" tabindex="-1">
<span id="thedefault" class="atmospherecheck">✔️</span>default</li>
<li data-val="pastel" tabindex="-1">
<span id="thepastel" class="atmospherecheck"></span>pastel</li>
<li data-val="darktwilight" tabindex="-1">
<span id="thedarktwilight" class="atmospherecheck"></span>twilight</li>
<li data-val="dark" tabindex="-1">
<span id="thedark" class="atmospherecheck"></span>dark</li>
<li data-val="darkmidnight" tabindex="-1">
<span id="thedarkmidnight" class="atmospherecheck"></span>midnight</li>
</ol>
</li>
<li data-env="ruler" tabindex="-1">Reading ruler<div class="wrap_to_submenu"><span class="to_submenu">▻</span></div>
<ol class="hidden ruler">
<li data-val="none" tabindex="-1">
<span id="thenone" class="rulercheck">✔️</span>none</li>
<li data-val="underline" tabindex="-1">
<span id="theunderline" class="rulercheck"></span>underline</li>
<li data-val="lunderline" tabindex="-1">
<span id="thelunderline" class="rulercheck"></span>L-underline</li>
<li data-val="greybar" tabindex="-1">
<span id="thegreybar" class="rulercheck"></span>grey bar</li>
<li data-val="lightbox" tabindex="-1">
<span id="thelightbox" class="rulercheck"></span>light box</li>
<li data-val="sunrise" tabindex="-1">
<span id="thesunrise" class="rulercheck"></span>sunrise</li>
<li data-val="sunriseunderline" tabindex="-1">
<span id="thesunriseunderline" class="rulercheck"></span>sunrise underline</li>
<li class="moveQ">Motion by:</li>
<li data-val="mouse" tabindex="-1">
<span id="themouse" class="motioncheck">✔️</span>follow the mouse</li>
<li data-val="arrow" tabindex="-1">
<span id="thearrow" class="motioncheck"></span>up/down arrows - not yet</li>
<li data-val="eye" tabindex="-1">
<span id="theeye" class="motioncheck"></span>eye tracking - not yet</li>
</ol>
</li>
</ol></div></button></span></nav><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\newcommand{\R}{\mathbb R}
\newcommand{\N}{\mathbb N}
\newcommand {\abs} [1] {\left| #1 \right|}
\newcommand {\Bernoulli}{\operatorname{Bernoulli}}
\newcommand {\binomial}{\operatorname{binomial}}
\newcommand {\geometric}{\operatorname{geometric}}
\newcommand {\NegBinom} {\operatorname{NegBinom}}
\newcommand {\Poisson} {\operatorname{Poisson}}
\newcommand {\var} {\operatorname{var}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<div class="ptx-page">
<div id="ptx-sidebar" class="ptx-sidebar"><nav id="ptx-toc" class="ptx-toc depth2"><ul class="structural">
<li><div class="toc-item"><a href="frontmatter.html" class="internal"><span class="title">Front Matter</span></a></div></li>
<li>
<div class="toc-item"><a href="prob-spaces.html" class="internal"><span class="codenumber">1</span> <span class="title">Probability spaces</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="prob-axioms.html" class="internal"><span class="codenumber">1.1</span> <span class="title">The Axioms of Probability</span></a></div></li>
<li>
<div class="toc-item"><a href="section-2.html" class="internal"><span class="codenumber">1.2</span> <span class="title">Conditional probability and independence</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-2.html#subsec-conditional-prob" class="internal"><span class="codenumber">1.2.1</span> <span class="title">Conditional Probability</span></a></div></li>
<li><div class="toc-item"><a href="section-2.html#subsec-independence" class="internal"><span class="codenumber">1.2.2</span> <span class="title">Independence</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="sec-more-examples.html" class="internal"><span class="codenumber">1.3</span> <span class="title">More Examples</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="ch-random-variables.html" class="internal"><span class="codenumber">2</span> <span class="title">Random variables</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-random-variables-theory.html" class="internal"><span class="codenumber">2.1</span> <span class="title">Random variables: definition and examples</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-random-variables-theory.html#subsec-random-variables" class="internal"><span class="codenumber">2.1.1</span> <span class="title">Random variables: the basics</span></a></div></li>
<li><div class="toc-item"><a href="sec-random-variables-theory.html#subsec-discrete-rvs" class="internal"><span class="codenumber">2.1.2</span> <span class="title">Discrete random variables</span></a></div></li>
<li><div class="toc-item"><a href="sec-random-variables-theory.html#subsec-cts-rvs" class="internal"><span class="codenumber">2.1.3</span> <span class="title">Continuous random variables</span></a></div></li>
</ul>
</li>
<li class="active">
<div class="toc-item"><a href="sec-discrete-rvs.html" class="internal"><span class="codenumber">2.2</span> <span class="title">Discrete random variables</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-discrete-rvs.html#subsec-expectation-discrete" class="internal"><span class="codenumber">2.2.1</span> <span class="title">The expectation of a discrete random variable</span></a></div></li>
<li><div class="toc-item"><a href="sec-discrete-rvs.html#subsec-poisson" class="internal"><span class="codenumber">2.2.2</span> <span class="title">The Poisson Distribution</span></a></div></li>
<li><div class="toc-item"><a href="sec-discrete-rvs.html#subsec-discrete-more-examples" class="internal"><span class="codenumber">2.2.3</span> <span class="title">More examples of discrete distributions</span></a></div></li>
<li><div class="toc-item"><a href="sec-discrete-rvs.html#subsec-variance-correlation" class="internal"><span class="codenumber">2.2.4</span> <span class="title">Correlation and variance</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="sec-cts-rvs.html" class="internal"><span class="codenumber">2.3</span> <span class="title">Continuous random variables</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="backmatter.html" class="internal"><span class="title">Backmatter</span></a></div></li>
</ul></nav></div>
<main class="ptx-main"><div id="ptx-content" class="ptx-content">
<section class="section" id="sec-discrete-rvs"><h2 class="heading hide-type">
<span class="type">Section</span><span class="space"> </span><span class="codenumber">2.2</span><span class="space"> </span><span class="title">Discrete random variables</span>
</h2>
<section class="introduction" id="introduction-1"><article class="example example-like" id="example-18"><h3 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.2.1</span><span class="period">.</span>
</h3>
<div class="para" id="p-110">We perform <span class="process-math">\(n\)</span> independent trials, each with a fixed probability <span class="process-math">\(p\)</span> of success. The total number of successes at the end is a <dfn class="terminology">binomial random variable</dfn> with parameters <span class="process-math">\(n\)</span> and <span class="process-math">\(p\text{;}\)</span> we write <span class="process-math">\(X \sim \binomial(n,p)\text{.}\)</span> Find its probability mass function.</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-12" id="solution-12"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-12"><div class="solution solution-like">
<div class="para logical" id="p-111">
<div class="para">Fix <span class="process-math">\(k \le n\text{.}\)</span> There are <span class="process-math">\(\binom nk\)</span>-many ways of choosing which of the <span class="process-math">\(k\)</span> trials will end in success. Then the probability that these <span class="process-math">\(k\)</span> trials succeed and the other <span class="process-math">\(n-k\)</span> fail is (by independence) <span class="process-math">\(p^k (1-p)^{n-k}\text{.}\)</span> Multiplying these gives the value <span class="process-math">\(p(k)\)</span> of the pmf at <span class="process-math">\(k\text{:}\)</span>
</div>
<div class="displaymath process-math">
\begin{equation*}
p(k) = \binom nk p^k (1-p)^{n-k}
\end{equation*}
</div>
<div class="para">You can view a graph of this pmf at <a class="external" href="https://www.geogebra.org/calculator/ykvdawbt" target="_blank">this GeoGebra link</a><a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-3" id="fn-3"><sup> 1 </sup></a>.</div>
</div> <div class="para" id="p-112">Later we will make precise the guess that the “center of mass” of this pmf occurs at <span class="process-math">\(p n\text{.}\)</span>
</div>
</div></div>
</div></article> <article class="exercise exercise-like" id="exercise-1"><a href="" data-knowl="" class="id-ref exercise-knowl original" data-refid="hk-exercise-1"></a></article><div class="hidden-content tex2jax_ignore" id="hk-exercise-1"><article class="exercise exercise-like"></article></div> <article class="definition definition-like" id="def-indep-rv"><h3 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">2.2.2</span><span class="period">.</span>
</h3>
<div class="para" id="p-114">Two random variables <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\)</span> on the same probability space are <dfn class="terminology">independent</dfn> if for all <span class="process-math">\(x,y\in\R\)</span> the events <span class="process-math">\(\{X \le x\}\)</span> and <span class="process-math">\(\{Y \le y\}\)</span> are independent.</div> <div class="para" id="p-115">If <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\)</span> are discrete, then it is equivalent to require that for all <span class="process-math">\(x,y\in\R\)</span> the events <span class="process-math">\(\{X = x\}\)</span> and <span class="process-math">\(\{Y = y\}\)</span> are independent.</div></article> <div class="para logical" id="p-116">
<div class="para">Then a random variable is <span class="process-math">\(\binomial(n,p)\)</span> if and only if it is a sum of <span class="process-math">\(n\)</span> independent <span class="process-math">\(\Bernoulli(p)\)</span> random variables:</div>
<div class="displaymath process-math">
\begin{equation*}
Y = X_1 + \cdots + X_n
\end{equation*}
</div>
</div> <article class="example example-like" id="example-19"><h3 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.2.3</span><span class="period">.</span>
</h3>
<div class="para" id="p-117">Independent trials are performed, each with a fixed probability <span class="process-math">\(p\)</span> of success. The number of trials required to see the first success is a <dfn class="terminology">geometric</dfn> random variable with parameter <span class="process-math">\(p\text{,}\)</span> and if it’s called <span class="process-math">\(X\)</span> then we write <span class="process-math">\(X \sim \geometric(p)\text{.}\)</span> Compute the pmf of a <span class="process-math">\(\geometric(p)\)</span> random variable.</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-13" id="solution-13"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-13"><div class="solution solution-like"><div class="para logical" id="p-118">
<div class="para">The possible values of <span class="process-math">\(X\)</span> are <span class="process-math">\(1,2,3,\dots\text{.}\)</span> Fix a positive integer <span class="process-math">\(k\text{.}\)</span> The probability that the first <span class="process-math">\(k-1\)</span> trials fail and the <span class="process-math">\(k\)</span>th succeeds is</div>
<div class="displaymath process-math">
\begin{equation*}
f(k) = (1-p)^{k-1} p
\end{equation*}
</div>
</div></div></div>
</div></article> <article class="exercise exercise-like" id="exercise-2"><a href="" data-knowl="" class="id-ref exercise-knowl original" data-refid="hk-exercise-2"></a></article><div class="hidden-content tex2jax_ignore" id="hk-exercise-2"><article class="exercise exercise-like"></article></div></section><section class="subsection" id="subsec-expectation-discrete"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">2.2.1</span><span class="space"> </span><span class="title">The expectation of a discrete random variable</span>
</h3>
<article class="definition definition-like" id="def-expectation-discrete"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">2.2.4</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-120">
<div class="para">The <dfn class="terminology">expected value</dfn>, <dfn class="terminology">expectation</dfn>, or <dfn class="terminology">mean</dfn> of a discrete random variable <span class="process-math">\(X\)</span> with pmf <span class="process-math">\(f\)</span> is defined as follows.</div>
<div class="displaymath process-math">
\begin{equation*}
E(X) = \sum_{x} xf(x) = \sum_i x_i p_i,
\end{equation*}
</div>
<div class="para">whenever this sum converges absolutely. (Otherwise the expected value does not exist.)</div>
</div></article><article class="exercise exercise-like" id="exercise-3"><a href="" data-knowl="" class="id-ref exercise-knowl original" data-refid="hk-exercise-3"><h4 class="heading">
<span class="type">Checkpoint</span><span class="space"> </span><span class="codenumber">2.2.5</span><span class="period">.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-exercise-3"><article class="exercise exercise-like"><div class="para" id="p-121">Verify that this agrees with the gradeschool notion of mean in the case <span class="process-math">\(p_1 = p_2 = \cdots = p_n = \tfrac1n\text{.}\)</span>
</div></article></div>
<article class="example example-like" id="example-20"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.2.6</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-122">
<div class="para">A <span class="process-math">\(\Bernoulli(p)\)</span> random variable has mean <span class="process-math">\(p\text{:}\)</span>
</div>
<div class="displaymath process-math">
\begin{equation*}
\sum_x x f(x) = 0\cdot f(0) + 1 \cdot f(1) = 0(1-p) + p = p.
\end{equation*}
</div>
</div> <div class="para" id="p-123">In particular, <span class="process-math">\(E(1_A) = P(A)\text{.}\)</span>
</div></article><article class="example example-like" id="example-21"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.2.7</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-124">
<div class="para">In order to compute the expectation of <span class="process-math">\(Y \sim \binomial(n,p)\text{,}\)</span> we must make sense of the following quantity.</div>
<div class="displaymath process-math">
\begin{equation*}
E(Y) = \sum_{k=0}^n k \binom nk p^k (1-p)^{n-k}
\end{equation*}
</div>
<div class="para">After some thought, we might notice that this is the following function of <span class="process-math">\(x\)</span> and <span class="process-math">\(y\)</span> evaluated at <span class="process-math">\(x = p\text{,}\)</span> <span class="process-math">\(y = 1-p\text{.}\)</span>
</div>
<div class="displaymath process-math" id="md-2">
\begin{align*}
\sum_{k=0}^n k \binom nk x^k y^{n-k}
\amp = x \frac{d}{dx} \sum_{k=0}^n \binom nk x^k y^{n-k} \\
\amp = x \frac{d}{dx} (x+y)^{n} \\
\amp = x n (x+y)^{n-1}  
\end{align*}
</div>
<div class="para">(We have used the Binomial Theorem.) Now, plugging in <span class="process-math">\(x = p\)</span> and <span class="process-math">\(y = 1-p\)</span> gives</div>
<div class="displaymath process-math">
\begin{equation*}
pn(p + 1-p)^{n-1} = pn.
\end{equation*}
</div>
<div class="para">But this is much easier using the linearity of expectation!</div>
</div></article><article class="theorem theorem-like" id="thm-linearity-expectation-discrete"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">2.2.8</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-125">
<div class="para">The expectation operator <span class="process-math">\(E\)</span> is linear; that is,</div>
<div class="displaymath process-math" id="md-3">
\begin{align*}
E(aX) \amp = a E(X) \\
\text{and} \quad E(X+Y) \amp = E(X) + E(Y) 
\end{align*}
</div>
</div></article><article class="hiddenproof" id="proof-3"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-3"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-3"><article class="hiddenproof"><div class="para" id="p-126">It is useful to notice that, for fixed <span class="process-math">\(x\in\R\text{,}\)</span> <span class="process-math">\(\{X = x\} = \bigcup_y \{X = x \text{ and } Y = y\}\text{,}\)</span> and that this is a disjoint union. Thus, by the additivity of the probability measure, <span class="process-math">\(P(X = x) = \sum_y P(X = x \text{ and } Y = y)\text{.}\)</span> We will use this fact and a similar one with the roles of <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\)</span> interchanged in what follows.</div> <div class="para logical" id="p-127">
<div class="displaymath process-math" id="md-4">
\begin{align*}
E(X+Y) \amp = \sum_z zP(X+Y = z)\\
\amp = \sum_x \sum_y (x+y) P(X = x \text{ and } Y = y) \\
\amp = \sum_x x \left[ \sum_y P(X = x \text{ and } Y = y) \right] 
+ \sum_y y \left[ \sum_x P(X = x \text{ and } Y = y) \right]\\
\amp = \sum_x x P(X = x) + \sum_y y P(Y = y)\\
\amp = E(X) + E(Y)
\end{align*}
</div>
<div class="para">The proof that <span class="process-math">\(E(aX) = aE(X)\)</span> is easier and is left as an exercise.</div>
</div></article></div>
<article class="example example-like" id="example-22"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.2.9</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-128">
<div class="para">Now it is much easier to compute the expectation of a binomial random variable: if <span class="process-math">\(Y \sim \binomial(n,p)\)</span> then there are independent <span class="process-math">\(\Bernoulli(p)\)</span> random variables <span class="process-math">\(X_1,\dots,X_n\)</span> of which <span class="process-math">\(Y\)</span> is the sum, and now we can use the linearity of expectation:</div>
<div class="displaymath process-math">
\begin{equation*}
E(Y) = E(X_1) + \cdots + E(X_n) = np.
\end{equation*}
</div>
</div></article><article class="lemma theorem-like" id="lem-lotus"><h4 class="heading">
<span class="type">Lemma</span><span class="space"> </span><span class="codenumber">2.2.10</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-129">
<div class="para">Suppose that <span class="process-math">\(X\)</span> is a discrete random variable with pmf <span class="process-math">\(f\)</span> and that <span class="process-math">\(g\colon\R\to\R\)</span> is any function. Then the expectation of the random variable <span class="process-math">\(g(X)\)</span> can be computed as follows.</div>
<div class="displaymath process-math">
\begin{equation*}
E(g(X)) = \sum_x g(x) f(x).
\end{equation*}
</div>
</div></article><article class="hiddenproof" id="proof-4"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-4"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-4"><article class="hiddenproof"><div class="para" id="p-130">Exercise.</div></article></div>
<article class="definition definition-like" id="def-moments"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">2.2.11</span><span class="period">.</span>
</h4>
<div class="para" id="p-131">Let <span class="process-math">\(X\)</span> be a random variable. For <span class="process-math">\(k\in\N\)</span> we define the <span class="process-math">\(k\)</span>th <dfn class="terminology">moment</dfn> of <span class="process-math">\(X\text{,}\)</span> denoted <span class="process-math">\(m_k(X)\text{,}\)</span> to be <span class="process-math">\(E(X^k)\text{.}\)</span> The <span class="process-math">\(k\)</span>th <dfn class="terminology">central moment</dfn> of <span class="process-math">\(X\text{,}\)</span> denoted <span class="process-math">\(\sigma_k(X)\text{,}\)</span> to be <span class="process-math">\(E((X- E(X))^k)\text{.}\)</span>
</div> <div class="para" id="p-132">Of particular note is <span class="process-math">\(\sigma_2 = E((X - E(X))^2) = \var(X)\text{,}\)</span> the <dfn class="terminology">variance</dfn> of <span class="process-math">\(X\text{.}\)</span>
</div></article><div class="para" id="p-133">The variance of <span class="process-math">\(X\)</span> measures the tendency of <span class="process-math">\(X\)</span> to deviate from its mean.</div>
<article class="exercise exercise-like" id="exercise-4"><a href="" data-knowl="" class="id-ref exercise-knowl original" data-refid="hk-exercise-4"><h4 class="heading">
<span class="type">Checkpoint</span><span class="space"> </span><span class="codenumber">2.2.12</span><span class="period">.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-exercise-4"><article class="exercise exercise-like"><div class="para" id="p-134">Show that <span class="process-math">\(\var(X) = E(X^2) - E(X)^2\text{.}\)</span>
</div></article></div>
<article class="example example-like" id="example-23"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.2.13</span><span class="period">.</span>
</h4>
<div class="para" id="p-135">Compute the variance of a <span class="process-math">\(\Bernoulli(p)\)</span> random variable.</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-14" id="solution-14"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-14"><div class="solution solution-like"><div class="para logical" id="p-136">
<div class="para">We see that</div>
<div class="displaymath process-math">
\begin{equation*}
E(X^2) = \sum_x x^2 f(x) = 0^2 (1-p) + 1^2 p = p,
\end{equation*}
</div>
<div class="para">so the variance is given by</div>
<div class="displaymath process-math">
\begin{equation*}
\var(X) = E(X^2) - E(X)^2 = p - p^2 = p(1-p).
\end{equation*}
</div>
</div></div></div>
</div></article><article class="example example-like" id="example-24"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.2.14</span><span class="period">.</span><span class="space"> </span><span class="title">Matching, revisited.</span>
</h4>
<div class="para logical" id="p-137">
<div class="para">Recall <a href="" class="xref" data-knowl="./knowl/ex-matching-hats.html" title="Example 1.3.3: Matching hats">Example 1.3.3</a>, in which we determined that, when <span class="process-math">\(n\)</span> people’s hats are randomly shuffled, the probability that at least one person gets their hat back is</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/ex-matching-hats.html">
\begin{equation*}
1 - \frac{1}{2!} + \frac{1}{3!} - \cdots + \frac{(-1)^{n+1}}{n!},
\end{equation*}
</div>
<div class="para">a quantity that tends as <span class="process-math">\(n\to\infty\)</span> to <span class="process-math">\(1 - \tfrac1e\text{.}\)</span>
</div>
</div> <div class="para" id="p-138">Now, letting <span class="process-math">\(X\)</span> be the number of people who receive their own hat, find <span class="process-math">\(E(X)\)</span> and <span class="process-math">\(\var(X)\text{.}\)</span>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-15" id="solution-15"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-15"><div class="solution solution-like">
<div class="para logical" id="p-139">
<div class="para">Consider, for <span class="process-math">\(k=1,\dots,n\text{,}\)</span> the following indicator random variable.</div>
<div class="displaymath process-math">
\begin{equation*}
I_k = \begin {cases}
1 \amp \text{ if the } k \text{th person gets his hat back} \\
0 \amp \text{ otherwise}
\end {cases}
\end{equation*}
</div>
<div class="para">Notice that <span class="process-math">\(E(I_k)\)</span> equals the probability that the <span class="process-math">\(k\)</span>th person gets their hat back, which as we discovered in the previous example is <span class="process-math">\(\tfrac1n\text{.}\)</span> Now we use the linearity of expectation:</div>
<div class="displaymath process-math">
\begin{equation*}
E(X) 
= E\left( \sum_{k=1}^n I_k \right)
= \sum_{k=1}^n E(X_k) = \sum_{k=1}^n \frac1n = 1.
\end{equation*}
</div>
</div> <div class="para logical" id="p-140">
<div class="displaymath process-math" id="md-5">
\begin{align*}
E(X^2) \amp = E \left[ \left( \sum_{k=1}^n I_k \right)^2 \right]\\
\amp = E \left[ \sum_{k=1}^n I_k^2 + \sum_{j\ne k} I_j I_k \right]\\
\amp = \sum_{k=1}^n E[I_k^2] + \sum_{j \ne k} E[I_j I_k]\\
\amp = \sum_{k=1}^n \frac{1}{n} + \sum_{j\ne k} \frac{1}{n(n-1)} \\
\amp = 1 + n(n-1)\frac{1}{n(n-1)}\\
\amp = 2
\end{align*}
</div>
<div class="para">For that we needed to compute <span class="process-math">\(E[I_j I_k]\text{:}\)</span>
</div>
<div class="displaymath process-math" id="md-6">
\begin{align*}
E(I_j I_k) \amp = 1P(\text{both } j \text{ and } k \text{ get their hat back}) + 0P(\text{at least one doesn't}) \\
\amp = 1\cdot \frac{1}{n(n-1)} + 0 
\end{align*}
</div>
<div class="para">Now we can conclude that</div>
<div class="displaymath process-math">
\begin{equation*}
\var(X) = E(X^2) - E(X)^2 = 2 - 1 = 1.
\end{equation*}
</div>
</div>
</div></div>
</div></article><article class="example example-like" id="example-25"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.2.15</span><span class="period">.</span><span class="space"> </span><span class="title">Coupon Collector.</span>
</h4>
<div class="para logical" id="p-141">
<div class="para">A fast-food restaurant offers kiddie meals that each include a toy. There are <span class="process-math">\(N\)</span> different toys available, and toys are equally likely to be in a given meal.</div>
<ol class="lower-alpha">
<li id="li-37"><div class="para" id="p-142">Find the expected number of meals needed to collect all the toys.</div></li>
<li id="li-38"><div class="para" id="p-143">Find the expected number of different toys collected if <span class="process-math">\(M\)</span> kiddie meals are purchased.</div></li>
</ol>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-16" id="solution-16"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-16"><div class="solution solution-like">
<div class="para" id="p-144">Let <span class="process-math">\(X\)</span> be the number of meals before all <span class="process-math">\(N\)</span> toys are collected. Then <span class="process-math">\(X = X_0 + X_1 + \cdots + X_{N-1}\text{,}\)</span> where <span class="process-math">\(X_k\)</span> is the number of additional meals after <span class="process-math">\(k\)</span> different toys have collected to get another toy. By linearity of expectation, <span class="process-math">\(E(X) = \sum_{k=0}^{N-1} E(X_k)\text{.}\)</span> Notice that <span class="process-math">\(X_k \sim \geometric\left(\frac{N-k}{N}\right)\text{,}\)</span> since after <span class="process-math">\(k\)</span> different toys have been collected, the chance of any particular meal giving us a new toy is <span class="process-math">\(\frac{N-k}{N}\text{.}\)</span>
</div> <div class="para logical" id="p-145">
<div class="para">Recalling that a <span class="process-math">\(\geometric(p)\)</span> random variable has expectation <span class="process-math">\(\tfrac1p\text{,}\)</span> we are now in position to compute the expectation of <span class="process-math">\(X\text{.}\)</span>
</div>
<div class="displaymath process-math" id="md-7">
\begin{align*}
E(X) \amp = \sum_{k=0}^{N-1} E(X_k) \\
\amp = 1 + \frac{N}{N-1} + \frac{N}{N-2} + \cdots + N\\
\amp = N\left( \frac{1}{N} + \frac{1}{N-1} + \cdots + 1\right) \\
\amp = N H(N) ,
\end{align*}
</div>
<div class="para">where <span class="process-math">\(H(N)\)</span> is the <span class="process-math">\(N\)</span>th <dfn class="terminology">harmonic number</dfn>. This quantity for <span class="process-math">\(N=6\)</span> is approximately <span class="process-math">\(15\)</span> and for <span class="process-math">\(N = 8\)</span> is approximately <span class="process-math">\(22\text{.}\)</span>
</div>
</div> <div class="para logical" id="p-146">
<div class="para">For part (b), let <span class="process-math">\(X\)</span> be the number of different toys collected if <span class="process-math">\(M\)</span> kiddie meals are purchased, and let <span class="process-math">\(Y = N - X\)</span> be the number of toys missing from the collection after <span class="process-math">\(M\)</span> meals. Then <span class="process-math">\(Y\)</span> can be written as a sum</div>
<div class="displaymath process-math">
\begin{equation*}
Y = Y_1 + \cdots + Y_N,
\end{equation*}
</div>
<div class="para">where</div>
<div class="displaymath process-math">
\begin{equation*}
Y_k = \begin {cases} 0 \amp \text{ if the } k \text{th toy is in the collection} \\
1 \amp \text{ if it's missing}
\end {cases}
\end{equation*}
</div>
<div class="para">Note that <span class="process-math">\(E(Y_k) = 1p+0(1-p) = p\text{,}\)</span> where <span class="process-math">\(p\)</span> is the probability that we didn’t get the <span class="process-math">\(k\)</span>th toy in <span class="process-math">\(M\)</span> meals, which is <span class="process-math">\(\left( \frac{N-1}{N}\right)^M\text{.}\)</span> Now <span class="process-math">\(E(Y) = \sum_{k=1}^N E(Y_k) = N\left(1-\frac{1}{N}\right)^M\text{.}\)</span> And we can compute the expected value of <span class="process-math">\(X\text{:}\)</span>
</div>
<div class="displaymath process-math">
\begin{equation*}
E(X) = N - E(Y) = N - N\left(1 - \frac{1}{N}\right)^M
\end{equation*}
</div>
<div class="para">Notice that this quantity approaches <span class="process-math">\(N\)</span> as <span class="process-math">\(M\to\infty\text{,}\)</span> as expected.</div>
</div>
</div></div>
</div></article></section><section class="subsection" id="subsec-poisson"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">2.2.2</span><span class="space"> </span><span class="title">The Poisson Distribution</span>
</h3>
<div class="para logical" id="p-147">
<div class="para">Consider <span class="process-math">\(X \sim \binomial(n,p)\)</span> and let <span class="process-math">\(n\to\infty\)</span> and <span class="process-math">\(p\to 0\)</span> while fixing <span class="process-math">\(\lambda = np\text{:}\)</span>
</div>
<div class="displaymath process-math" id="md-8">
\begin{align*}
\binom nk p^k (1-p)^{n-k} \amp = \binom nk \left( \frac{\lambda}{n} \right)^k \left( 1 - \frac{\lambda}{n}\right)^{n-k} \\
\amp = \frac{n(n-1)(n-2)\cdots(n-k+1)}{k!} \cdot \frac{\lambda^k}{n^k}\left( 1 - \frac{\lambda}{n}\right)^n \left( 1 - \frac{\lambda}{n}\right)^{-k}\\
\amp = \frac{n(n-1)(n-2)\cdots(n-k+1)}{n^k} \cdot \frac{\lambda^k}{k!}\left( 1 - \frac{\lambda}{n}\right)^n \left( 1 - \frac{\lambda}{n}\right)^{-k}\\
\amp \underset{n\to\infty}{\longrightarrow} 1 \cdot \frac{\lambda^k}{k!} \cdot e^{-\lambda} \cdot 1
= \frac{\lambda^k}{k!} e^{-\lambda} 
\end{align*}
</div>
</div>
<article class="definition definition-like" id="def-poisson"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">2.2.16</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-148">
<div class="para">A random variable is said to follow a <dfn class="terminology">Poisson</dfn> distribution with parameter <span class="process-math">\(\lambda\in (0,\infty)\)</span> if its pmf <span class="process-math">\(f\)</span> is given by</div>
<div class="displaymath process-math">
\begin{equation*}
f(k) = \frac{\lambda^k}{k!} e^{-\lambda}
\end{equation*}
</div>
</div></article><div class="para" id="p-149">A <span class="process-math">\(\Poisson(\lambda)\)</span> random variable is a good model for a rare event that occurs on average <span class="process-math">\(\lambda\)</span> times per unit time.</div>
<article class="exercise exercise-like" id="exercise-5"><a href="" data-knowl="" class="id-ref exercise-knowl original" data-refid="hk-exercise-5"><h4 class="heading">
<span class="type">Checkpoint</span><span class="space"> </span><span class="codenumber">2.2.17</span><span class="period">.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-exercise-5"><article class="exercise exercise-like"><div class="para" id="p-150">Verify that <span class="process-math">\(\sum_{k\ge 0} \frac{\lambda^k}{k!} e^{-\lambda} = 1\text{.}\)</span>
</div></article></div>
<article class="example example-like" id="example-26"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.2.18</span><span class="period">.</span>
</h4>
<div class="para" id="p-151">Compute the expected value of a <span class="process-math">\(\Poisson(\lambda)\)</span> random variable.</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-17" id="solution-17"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-17"><div class="solution solution-like"><div class="para logical" id="p-152"><div class="displaymath process-math" id="md-9">
\begin{align*}
E(X) \amp = \sum_{k\ge 0} k f(k) \\
\amp = \sum_{k\ge 0} k \frac{\lambda^k}{k!} e^{-\lambda} \\
\amp = \lambda e^{-\lambda} \sum_{k\ge 1} \frac{\lambda^{k-1}}{(k-1)!}\\
\amp = \lambda e^{-\lambda} \sum_{m\ge0} \frac{\lambda^m}{m!} \\
\amp = \lambda e^{-\lambda} e^{\lambda} \\
\amp = \lambda 
\end{align*}
</div></div></div></div>
</div></article><article class="exercise exercise-like" id="exercise-6"><a href="" data-knowl="" class="id-ref exercise-knowl original" data-refid="hk-exercise-6"><h4 class="heading">
<span class="type">Checkpoint</span><span class="space"> </span><span class="codenumber">2.2.19</span><span class="period">.</span>
</h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-exercise-6"><article class="exercise exercise-like"><div class="para" id="p-153">Show that <span class="process-math">\(\var(X) = \lambda\)</span> too.</div></article></div>
<article class="example example-like" id="example-27"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.2.20</span><span class="period">.</span>
</h4>
<div class="para" id="p-154">Astronomers estimate that on average one large meteorite hits Earth every 100 years. Compute the probability that no large meteorite hits Earth in the next 100 years.</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-18" id="solution-18"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-18"><div class="solution solution-like"><div class="para" id="p-155">We model the number of meteorites coming in the next century by a <span class="process-math">\(\Poisson(1)\)</span> random variable. The probability that no meteorite comes in the next century is <span class="process-math">\(\frac{1e^{-1}}{0!} = \frac{1}{e} \approx 0.37\text{.}\)</span> This means there is a <span class="process-math">\(63\%\)</span> chance that at least one meteorite will hit in the next 100 years.</div></div></div>
</div></article><article class="example example-like" id="example-28"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.2.21</span><span class="period">.</span>
</h4>
<div class="para" id="p-156">Our observations indicate that on average <span class="process-math">\(1\)</span> gram of radioactive material discharges <span class="process-math">\(3.2\)</span> ɑ particles per second. Compute the probability that at most two ɑ particles will appear.</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-19" id="solution-19"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-19"><div class="solution solution-like"><div class="para logical" id="p-157">
<div class="displaymath process-math" id="md-10">
\begin{align*}
P(E) \amp = f(0) + f(1) + f(2) \\
\amp = e^{-3.2} + 3.2 e^{-3.2} + \frac{3.2^2}{2!}e^{-3.2} \\
\amp \approx 0.3799 
\end{align*}
</div>
<div class="para">So approximately a <span class="process-math">\(38\%\)</span> chance.</div>
</div></div></div>
</div></article><article class="example example-like" id="example-29"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.2.22</span><span class="period">.</span><span class="space"> </span><span class="title">Poisson Coin Flips.</span>
</h4>
<div class="para" id="p-158">Suppose that a coin with probability <span class="process-math">\(p\)</span> of showing heads is tossed <span class="process-math">\(N\)</span> times. Let <span class="process-math">\(X\)</span> be the number of heads and <span class="process-math">\(Y\)</span> the number of tails. Then <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\)</span> are certainly not independent; from the value of one we can compute the value of the other!</div> <div class="para" id="p-159">Nonetheless, show that if we toss the coin a <em class="emphasis">random</em> number <span class="process-math">\(N \sim \Poisson(\lambda)\)</span> of times, then <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\)</span> are independent!</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-20" id="solution-20"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-20"><div class="solution solution-like"><div class="para logical" id="p-160">
<div class="para">We must show for all <span class="process-math">\(k,l\)</span> that the events <span class="process-math">\(\{X = k\}\)</span> and <span class="process-math">\(\{Y = l\}\)</span> are independent, i.e., that</div>
<div class="displaymath process-math">
\begin{equation*}
P(X = k \text{ and } Y = l) = P(X = k) P(Y = l).
\end{equation*}
</div>
<div class="para">Start with the lefthand side:</div>
<div class="displaymath process-math" id="md-11">
\begin{align*}
P(X = k \text{ and } Y = l) \amp = P(X = k \text{ and } Y = l \mid N = k+l)P(N = k+l) \\
\amp = \binom{k+l}{l} p^k (1-p)^l \frac{\lambda^{k+l}}{(k+l)!} e^{-\lambda} \\
\amp = \frac{(k+l)!}{k! l!} p^k (1-p)^l \frac{\lambda^{k+l}}{(k+l)!} e^{-\lambda} \\
\amp = \frac{ (p\lambda)^k ((1-p)\lambda)^l}{k! l! } e^{-\lambda}
\end{align*}
</div>
<div class="para">Toward the righthand side, start by using the Law of Total Probability:</div>
<div class="displaymath process-math" id="md-12">
\begin{align*}
P(X = k) \amp = \sum_{n \ge k} P(X = k \mid N = n) P(N = n) \\
\amp = \sum_{n\ge k} \binom nk p^k (1-p)^{n-k} \frac{\lambda^n}{n!} e^{-\lambda} \\
\amp = \frac{p^k e^{-\lambda}}{k!} \lambda^k \sum_{n \ge k} \frac{(1-p)^{n-k}}{(n-k)!} \lambda^{n-k} \\
\amp = \frac{p^k e^{-\lambda}}{k!} \lambda^k \sum_{m \ge 0} \frac{(1-p)^m}{m!} \lambda^m \\
\amp = \frac{(\lambda p)^k e^{-\lambda p}}{k!} 
\end{align*}
</div>
<div class="para">Similarly,</div>
<div class="displaymath process-math">
\begin{equation*}
P(Y = l) = \frac{ (\lambda(1-p))^l e^{-\lambda(1-p)}}{l !}
\end{equation*}
</div>
<div class="para">Combining all this, we get:</div>
<div class="displaymath process-math">
\begin{equation*}
P(X = k)P(Y = l) = \frac{(\lambda p)^k (\lambda(1-p))^l e^{-\lambda}}{ k! l!} = P(X = k \text{ and } Y = l)
\end{equation*}
</div>
</div></div></div>
</div></article></section><section class="subsection" id="subsec-discrete-more-examples"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">2.2.3</span><span class="space"> </span><span class="title">More examples of discrete distributions</span>
</h3>
<article class="definition definition-like" id="def-neg-binom"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">2.2.23</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-161">
<div class="para">Independent <span class="process-math">\(\Bernoulli(p)\)</span> trials are performed until a total of <span class="process-math">\(r\)</span> successes are achieved. Let <span class="process-math">\(X\)</span> be the number of trials required. Notice that the pmf of <span class="process-math">\(X\)</span> is given by the following formula.</div>
<div class="displaymath process-math">
\begin{equation*}
P(X = n) = \binom{n-1}{r-1} p^r (1-p)^{n-r}, \qquad n=r,r+1,\dots
\end{equation*}
</div>
<div class="para">(The <span class="process-math">\(n\)</span>th trial must be a success; there are <span class="process-math">\(\binom{n-1}{r-1}\)</span> many ways to choose which of the remaining trials succeed; then the chance that the trials that are supposed to succeed do succeed and the others fail is <span class="process-math">\(p^r (1-p)^{n-r}\text{.}\)</span>)</div>
</div> <div class="para" id="p-162">A random variable with this pmf is said to follow a <dfn class="terminology">negative binomial</dfn> distribution with parameters <span class="process-math">\(r\)</span> and <span class="process-math">\(p\text{;}\)</span> we write <span class="process-math">\(X \sim \NegBinom(r,p)\text{.}\)</span>
</div></article></section><section class="subsection" id="subsec-variance-correlation"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">2.2.4</span><span class="space"> </span><span class="title">Correlation and variance</span>
</h3>
<div class="para" id="p-163">Recall that <span class="process-math">\(\var(X)\)</span> is defined to be <span class="process-math">\(E((X-E(X))^2)\)</span> and is equal to <span class="process-math">\(E(X^2) - E(X)^2\text{.}\)</span> We should not expect this statistic to be linear, since as we will verify we expect <span class="process-math">\(\var(aX) = a^2 \var(X)\text{.}\)</span> But it is natural to wonder under what conditions it is <em class="emphasis">additive</em>, meaning <span class="process-math">\(\var(X+Y) = \var(X) + \var(Y)\text{.}\)</span>
</div>
<article class="definition definition-like" id="def-uncorrelated"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">2.2.24</span><span class="period">.</span>
</h4>
<div class="para" id="p-164">Two random variables <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\)</span> are <dfn class="terminology">uncorrelated</dfn> if <span class="process-math">\(E(XY) = E(X)E(Y)\text{.}\)</span>
</div></article><article class="lemma theorem-like" id="lem-independent-uncorrelated"><h4 class="heading">
<span class="type">Lemma</span><span class="space"> </span><span class="codenumber">2.2.25</span><span class="period">.</span>
</h4>
<div class="para" id="p-165">If <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\)</span> are independent, then they are uncorrelated.</div></article><article class="hiddenproof" id="proof-5"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-5"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-5"><article class="hiddenproof"><div class="para logical" id="p-166"><div class="displaymath process-math" id="md-13">
\begin{align*}
E(XY) \amp = \sum_{x,y} xy P(X = x \text{ and } Y = y) \\
\amp = \sum_{x,y} xy P(X = x) P(Y = y) \\
\amp = \sum_{x} x P(X = x) \sum_y y P(Y = y) \\
\amp = E(X) E(Y) 
\end{align*}
</div></div></article></div>
<div class="para" id="p-167">The converse is false!</div>
<article class="example example-like" id="example-30"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.2.26</span><span class="period">.</span>
</h4>
<div class="para" id="p-168">Let <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\)</span> be independent Bernoulli random variables with parameter <span class="process-math">\(1/2\text{.}\)</span> Show that <span class="process-math">\(X+Y\)</span> and <span class="process-math">\(\abs{X-Y}\)</span> are dependent but uncorrelated.</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-21" id="solution-21"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-21"><div class="solution solution-like">
<div class="para" id="p-169">To show that <span class="process-math">\(X+Y\)</span> and <span class="process-math">\(\abs{X-Y}\)</span> are dependent, it is enough to show that the events <span class="process-math">\(\{X+Y = 0\}\)</span> and <span class="process-math">\(\{\abs{X-Y} = 0\}\)</span> are dependent. But of course! The only way for <span class="process-math">\(X+Y\)</span> to equal <span class="process-math">\(0\)</span> is for <span class="process-math">\(X = Y = 0\text{,}\)</span> and this implies that <span class="process-math">\(\abs{X-Y} = 0\text{.}\)</span> In other words, <span class="process-math">\(P(X+Y = 0 \text{ and } \abs{X-Y} = 0) = 
P(X+Y = 0) = \tfrac14\)</span> and <span class="process-math">\(P(\abs{X-Y}=0) = \tfrac12\text{,}\)</span> and <span class="process-math">\(\tfrac14 \cdot \tfrac12 \ne \tfrac14\text{.}\)</span>
</div> <div class="para logical" id="p-170">
<div class="para">To see that <span class="process-math">\(X+Y\)</span> and <span class="process-math">\(\abs{X-Y}\)</span> are uncorrelated, we compute all the relevant expected values by hand:</div>
<div class="displaymath process-math">
\begin{equation*}
E(X+Y) = E(X) + E(Y) = \tfrac12 + \tfrac12 = 1.
\end{equation*}
</div>
<div class="displaymath process-math">
\begin{equation*}
E(\abs{X-Y}) = 0P(\abs{X-Y}=0) + 1P(\abs{X-Y} = 1) = \tfrac12
\end{equation*}
</div>
<div class="displaymath process-math">
\begin{equation*}
E(\abs{X-Y}(X+Y)) = 0P(Z = 0) + 1P(Z = 1) + 2P(Z = 2)
= 1P(\abs{X-Y}(X+Y)=1) = \tfrac12
\end{equation*}
</div>
<div class="para">And <span class="process-math">\(\tfrac12 \cdot 1 = \tfrac12\text{,}\)</span> so <span class="process-math">\(X+Y\)</span> and <span class="process-math">\(\abs{X-Y}\)</span> are uncorrelated.</div>
</div>
</div></div>
</div></article><div class="para" id="p-171">And here is the reason for making the definition:</div>
<article class="proposition theorem-like" id="prop-variance-uncorrelated"><h4 class="heading">
<span class="type">Proposition</span><span class="space"> </span><span class="codenumber">2.2.27</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-172"><ol class="lower-alpha">
<li id="li-39"><div class="para" id="p-173"><span class="process-math">\(\displaystyle \var(aX) = a^2 \var(X)\)</span></div></li>
<li id="li-40"><div class="para" id="p-174">If <span class="process-math">\(X\)</span> and <span class="process-math">\(Y\)</span> are uncorrelated, then <span class="process-math">\(\var(X+Y) = \var(X) + \var(Y)\text{.}\)</span>
</div></li>
</ol></div></article><article class="hiddenproof" id="proof-6"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-6"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-6"><article class="hiddenproof"><div class="para logical" id="p-175">
<div class="para">The first part follows immediately from the definition of variance and the linearity of expectation:</div>
<div class="displaymath process-math">
\begin{equation*}
\var(aX) = E((aX - E(aX)^2))
= E(a^2 (X - E(X))^2)
= a^2 \var(X)
\end{equation*}
</div>
</div> <div class="para logical" id="p-176">
<div class="para">The second part follows from our other characterization of variance:</div>
<div class="displaymath process-math" id="md-14">
\begin{align*}
\var(X+Y) \amp = E((X+Y)^2) - (E(X+Y))^2 \\
\amp = E(X^2 + 2XY + Y^2) - E(X)^2 - 2E(X)E(Y) - E(Y)^2 \\
\amp = E(X^2) + 2E(XY) + E(Y^2) - E(X)^2 - 2E(X)E(Y) - E(Y)^2 \\
\amp = \var(X) + \var(Y) 
\end{align*}
</div>
<div class="para">That’s it.</div>
</div></article></div>
<article class="example example-like" id="example-31"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.2.28</span><span class="period">.</span>
</h4>
<div class="para" id="p-177">A <span class="process-math">\(\binomial(n,p)\)</span> random variable <span class="process-math">\(X\)</span> can be expressed as a sum <span class="process-math">\(X = X_1 + \cdots + X_n\)</span> of independent <span class="process-math">\(\Bernoulli(p)\)</span> random variables. Recall that the variance of a <span class="process-math">\(\Bernoulli(p)\)</span> random variable is <span class="process-math">\(p(1-p)\text{.}\)</span> Since the <span class="process-math">\(X_k\)</span> are independent, they are uncorrelated. So <span class="process-math">\(\var(X) = \sum_{k=1}^n p(1-p) = np(1-p)\text{.}\)</span>
</div></article></section></section><div class="hidden-content tex2jax_ignore" id="hk-fn-3"><div class="fn"><code class="code-inline tex2jax_ignore">geogebra.org</code></div></div>
</div>
<div class="ptx-content-footer">
<a class="previous-button button" href="sec-random-variables-theory.html" title="Previous"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cb;</span><span class="name">Prev</span></a><a class="top-button button" href="#" title="Top"><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5ce;</span><span class="name">Top</span></a><a class="next-button button" href="sec-cts-rvs.html" title="Next"><span class="name">Next</span><span class="icon material-symbols-outlined" aria-hidden="true">&#xe5cc;</span></a>
</div></main>
</div>
<div id="ptx-page-footer" class="ptx-page-footer">
<a class="pretext-link" href="https://pretextbook.org" title="PreTeXt"><div class="logo"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="338 3000 8772 6866"><g style="stroke-width:.025in; stroke:black; fill:none"><polyline points="472,3590 472,9732 " style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round; "></polyline><path style="stroke:#000000;stroke-width:126;stroke-linecap:butt;" d="M 4724,9448 A 4660 4660  0  0  1  8598  9259"></path><path style="stroke:#000000;stroke-width:174;stroke-linecap:butt;" d="M 4488,9685 A 4228 4228  0  0  0   472  9732"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:butt;" d="M 4724,3590 A 4241 4241  0  0  1  8598  3496"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:round;" d="M 850,3496  A 4241 4241  0  0  1  4724  3590"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:round;" d="M 850,9259  A 4507 4507  0  0  1  4724  9448"></path><polyline points="5385,4299 4062,8125" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8598,3496 8598,9259" style="stroke:#000000;stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="850,3496 850,9259" style="stroke:#000000;stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="4960,9685 4488,9685" style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="3070,4582 1889,6141 3070,7700" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="6418,4582 7600,6141 6418,7700" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8976,3590 8976,9732" style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><path style="stroke:#000000;stroke-width:174;stroke-linecap:butt;" d="M 4960,9685 A 4228 4228  0  0  1  8976  9732"></path></g></svg></div></a><a class="runestone-link" href="https://runestone.academy" title="Runestone Academy"><img class="logo" src="https://runestone.academy/runestone/static/images/RAIcon_cropped.png"></a><a class="mathjax-link" href="https://www.mathjax.org" title="MathJax"><img class="logo" src="https://www.mathjax.org/badge/badge-square-2.png"></a>
</div>
</body>
</html>
