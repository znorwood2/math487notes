<?xml version='1.0' encoding='utf-8'?>

<pretext xml:lang="en-US" xmlns:xi="http://www.w3.org/2001/XInclude">

  <docinfo>
    <macros>
      \newcommand{\R}{\mathbb R}
      \newcommand{\N}{\mathbb N}
      \newcommand {\abs} [1] {\left| #1 \right|}
      \newcommand {\Bernoulli}{\operatorname{Bernoulli}}
      \newcommand {\binomial}{\operatorname{binomial}}
      \newcommand {\geometric}{\operatorname{geometric}}
      \newcommand {\NegBinom} {\operatorname{NegBinom}}
      \newcommand {\Poisson} {\operatorname{Poisson}}
      \newcommand {\gauss} {\mathcal{N}}
      \newcommand {\var} {\operatorname{var}}
      \newcommand {\cov} {\operatorname{cov}}
    </macros>
    <latex-image-preamble>
      \usepackage{tikz}
    </latex-image-preamble>
      <brandlogo source="dice.png" />
  </docinfo>

  <book xml:id="math-487-notes">
    <title>Math 487 at UNL</title>
    <subtitle>Fall 2023 lecture notes</subtitle>

    <frontmatter xml:id="frontmatter">
      <titlepage>
        <author>
          <personname>Zach Norwood</personname>
          <department>Department of Mathematics</department>
          <institution>University of Nebraska<ndash/>Lincoln</institution>
        </author>
        <date>
          <today />
        </date>
      </titlepage>

      <colophon>

        <website>
          <url href="https://math.unl.edu"></url>
          <!-- <name>
            <c>math.unl.edu</c>
          </name>
          <address>https://math.unl.edu</address> -->
        </website>

        <copyright>
          <year>2020<ndash />2023</year>
          <holder>Zach Norwood</holder>
          <shortlicense> 
            This work is licensed under the Creative Commons Attribution-ShareAlike 4.0 International License.
            To view a copy of this license, 
            visit <url href="http://creativecommons.org/licenses/by-sa/4.0/" visual="creativecommons.org/licenses/by-sa/4.0"> CreativeCommons.org</url>
          </shortlicense>
        </copyright>
      </colophon>
    </frontmatter>

    <chapter xml:id="prob-spaces">
      <title>Probability spaces</title>

      <section xml:id="prob-axioms">
        <title>The Axioms of Probability</title>
        <p>
          Intuition can mislead us, particularly in probability, so we make an effort 
          to be careful from the start.
        </p>
        <p>
          But let's motivate the definition and consider an example or two before we give it
          precisely.
          To describe an experiment or trial with random outcomes, we need three things.
        </p>
        <p>
          <ol>
          <li>
            <p>
              A <em>sample space</em> <m>\Omega</m>, the set of all possible <em>outcomes</em>.
            </p>
          </li>
          <li>
            <p>
              A family <m>\mathcal{F}\subseteq 2^{\Omega}</m> of permissible <em>events</em>.
              (It is less obvious that we need this.)
              By <m>2^\Omega</m> we mean the powerset of <m>\Omega</m>.
            </p>
          </li>
          <li>
            <p>
              An assignment <m>P</m> of probabilities (numbers) to events.
            </p>
          </li>
        </ol>
      </p>
      <example>
        <statement>
        <p>Toss a fair coin 3 times. What is the probability that you see exactly two heads?</p>
        </statement>
        <solution>
          <p>
            What are the possible outcomes of this experiment?
          <me>
            \Omega = \{ HHH, HHT, HTH, THH, TTH, THT, HTT, TTT \}
          </me>
          to be finished
        </p>
        </solution>
      </example>
      <example>
        <statement>
          <p>
            My neighbor and I each leave home, independently, between 8 and 9am,
            where any time is equally likely. What is the probability that she leaves
            at least 20 minutes before I do?
          </p>
        </statement>
        <solution>
          <p></p>
        </solution>
      </example>

      <definition xml:id="def-prob-space">
        <statement>
        <p>
          A <term>probability measure</term> <m>P</m> on <m>(\Omega,\mathcal{F})</m>, where <m>\Omega</m>
          is a set and <m>\mathcal{F}</m> is a <term><m>\sigma</m>-field</term> of subsets of <m>\Omega</m>,
          is a function <m>P\colon \mathcal{F} \to [0,1]</m> satisfying the following properties.
          <ol marker="(a)">
            <li>
              <p>
                <m>P(\Omega) = 1</m>
              </p>
            </li>
            <li>
              <p>
                <m>P</m> is <term>countably additive</term>, meaning that for any countably infinite
                list <m>A_1,A_2,\dots</m> of pairwise disjoint (<m>i\ne j</m> implies <m>A_i \cap A_j = \emptyset</m>)
                members of <m>\mathcal{F}</m>, we have
                <me>P\left( \bigcup_{n \ge 1} A_i \right) = \sum_{n\ge 1} P(A_n).</me>
              </p>
            </li>
          </ol>
        </p>
      </statement>
      </definition>
      <p>
        The two conditions in <xref ref="def-prob-space"/> together with the fact that <m>P(A) \ge 0</m> for
        every <m>A \in \mathcal{F}</m> are often called the three Axioms of Probability.
      </p>
      <definition>
        <statement>
          <p>
            A collection <m>\mathcal{F}</m> of subsets of <m>\Omega</m> is a <term><m>\sigma</m>-field</term>
            if it satisfies the following three conditions.
            <ol>
              <li>
                <p>
                  <m>\emptyset\in\mathcal{F}</m>
                </p>
              </li>
              <li><p>If <m>A_1,A_2,\dots\in\mathcal{F}</m> then <m>\bigcup_{n\ge 1} A_n \in \mathcal{F}</m>
              (<term>closure under countable unions</term>).</p></li>
              <li>
                <p>
                  If <m>A\in\mathcal{F}</m> then <m>A^c \in \mathcal{F}</m>.
                </p>
              </li>
            </ol>
          </p>
        </statement>
      </definition>
      </section>
      <section>
        <title>Conditional probability and independence</title>
        <subsection xml:id="subsec-conditional-prob">
          <title>Conditional Probability</title>
        <definition xml:id="def-conditional-prob">
          <statement>
            <p>
              If <m>P(B) \gt 0</m> then the <term>conditional probability of <m>A</m> given <m>B</m></term>,
              written <m>P(A | B)</m>, is the quantity
              <me>P(A | B) = \frac{P(A\cap B)}{P(B)} .</me>
            </p>
          </statement>
        </definition>
        <p>Note that the rearranged form <m>P(A\cap B) = P(A | B) P(B)</m> of the equation can be useful.</p>
        <example>
          <statement>
            <p>
              In September 40% of days are warm and the rest are cool.
              On warm days there is a 60% chance of rain; on cool days there is a 30% chance.
              <ol>
                <li>
                  <p>
                    What is the probability that it will rain on a September day?
                  </p>
                </li>
                <li>
                  <p>What is the probability that it is warm, given that it is raining?</p>
                </li>
              </ol>
            </p>
          </statement>
          <solution>
            <p>
              <!-- to be added -->
            </p>
          </solution>
        </example>
        <theorem xml:id="thm-law-total-prob">
          <title>The Law of Total Probability</title>
          <statement>
            <p>
              Suppose that events <m>B_1,\dots,B_n</m> partition <m>\Omega</m>.
              Then for any event <m>A</m> we have
              <me>P(A) = \sum_{i=1}^n P(A | B_i) P(B_i) = \sum_{i=1}^n P(A\cap B_i) .</me>
            </p>
          </statement>
        </theorem>
      </subsection>
        <subsection xml:id="subsec-independence">
          <title>Independence</title>
          <definition xml:id="def-independence">
            <statement>
              <p>
                Events <m>A</m> and <m>B</m> in a probability space are <term>independent</term>
                if <m>P(A\cap B) = P(A)P(B)</m>.
              </p>
              <p>
                More generally, events <m>A_i</m>, <m>i\in I</m>, are <term>mutually independent</term>
                if for any finite subset <m>J \subseteq I</m> we have
                <me>
                  P\left( \bigcap_{i\in J} A_i \right) = \prod_{i\in J} P(A_i).
                </me>
                The <m>A_i</m> are said to be <term>pairwise independent</term> if for any distinct indices <m>i,j\in I</m>
                the two events <m>A_i</m> and <m>A_j</m> are independent.
              </p>
            </statement>
          </definition>
          <remark>
            <p>
            <ul>
              <li>
                <p>
                  Notice that <m>P(A\cap B) = P(A | B) P(B) = P(B | A) P(A)</m>. So, as long as <m>P(A) \gt 0</m>
                  and <m>P(B) \gt 0</m> the independence of <m>A</m> and <m>B</m> is equivalent to 
                  either <m>P(A | B) = P(A)</m> or <m>P(B | A) = P(B)</m>; that is,
                  information about either event doesn't change the probability of the other.
                </p>
              </li>
              <li>
                <p>
                  Independence is not the same as disjointness; independent events <m>A</m> and <m>B</m>
                  may or may not satisfy <m>A \cap B = \emptyset</m>.
                </p>
              </li>
            </ul>
          </p>
          </remark>
          <example>
            <statement>
              <p>
                Roll two fair 6-sided dice.
                Let <m>A</m> denote the event that the first roll is a 3, 
                <m>B</m> denote the event that the second roll is a 4,
                and <m>C</m> denote the event that the sum of the two rolls equals 7.
              </p>
              <p>
                The events <m>A</m> and <m>B</m> are certainly independent:
                of the 36 possible outcomes, 6 are in <m>A</m> and 6 are in <m>B</m>;
                and exactly 1 is common to <m>A</m> and <m>B</m>.
              </p>
              <p>
                Show that the three events <m>A</m>, <m>B</m>, and <m>C</m>
                are <em>pairwise</em> but not <em>mutually</em> independent.
              </p>
            </statement>
            <solution>
              <p>
                That <m>A</m> and <m>B</m> are independent is explained in the statement of the example.
                For <m>A</m> and <m>C</m>, first notice that <m>P(A) = P(B) = P(C) = \tfrac16</m>.
                Then notice that <m>A \cap C = A \cap B</m> and so we have
                <me>
                  P(A \cap C) = P(A \cap B) = P(A) P(B) = P(A) P(C).
                </me>
                A similar argument shows that <m>B</m> and <m>C</m> are independent.
              </p>
              <p>
                But <m>A \cap B \cap C = A \cap B</m>, so the three events are not mutually independent:
                <me>
                  P(A \cap B \cap C) = P(A \cap B) = \tfrac{1}{36} \ne (\tfrac16)^3.
                </me>
              </p>
            </solution>
          </example>
          <example>
            <statement>
              <p>
                Draw one card from a standard 52-card deck. Show that suit is independent of rank;
                for example, show that drawing a jack is independent of drawing a heart.
              </p>
            </statement>
            <solution>
              <p>
                The probability of drawing a jack is <m>\tfrac{4}{52} = \tfrac{1}{13}</m>, and the probability
                of drawing a heart is <m>\tfrac{13}{52} = \tfrac14</m>.
                The probability of drawing the Jack of Hearts is <m>\tfrac{1}{52} = \tfrac{1}{13} \cdot \tfrac{1}{4}</m>.
              </p>
            </solution>
          </example>
        </subsection>
      </section>
    <section xml:id="sec-more-examples">
          <title>More Examples</title>
          <example>
            <title>Poker hands</title>
            <statement>
              <p>
                A standard deck of cards (for the purposes of this class) comprises 52 cards.
                Each card has a <term>rank</term> and a <term>suit</term>.
                The 13 possible ranks are Ace, 2<ndash/>10, Jack, Queen, and King,
                and the 4 possible suits are hearts ♥️, diamonds ♦️, spades ♠️,
                and clubs ♣️. Each possible pairing of rank and suit is realized in exactly one card.
              </p>
              <p>
                From a standard deck of 52 cards draw a 5-card hand.
                (Both the deck and the hand are thought of as <em>sets</em>, so order is irrelevant.)
              </p>
              <p>
                <ol>
                  <li>
                    <p>
                      What is the probability that your hand is a <term>full house</term>,
                      i.e., takes the form AAABB where A and B are different ranks?
                      (E.g. three 3s and two Queens makes a full house, no matter what the suits of the cards are.)
                    </p>
                  </li>
                  <li>
                    <p>
                      What is the probability that you hold <term>two pairs</term>,
                      i.e., ranks AABBC where A, B, and C represent different ranks?
                      (E.g. 3377K is two pairs, no matter what the suits, but 3337K is three of a kind.)
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
            <solution>
              <p>
                There are many ways to count full houses, but the simplest is probably to choose the 
                two ranks first, first the rank of the triplet and then the rank of the pair.
                There are 13 ways of choosing the rank A of the triplet, leaving 12 possibilities for the
                rank B of the pair. Then there are <m>\binom{4}{3}</m> possible triplets of cards of rank
                A and <m>\binom{4}{2}</m> possible pairs of cards of rank B. We can now compute the total
                probability:
                <me>
                  \frac{13 \cdot 12 \cdot \binom{4}{3} \binom{4}{2}}{\binom{52}{5}}
                  = \frac{13 \cdot 12 \cdot 4 \cdot 6}{\binom{52}{5}}
                  \approx 0.0014
                </me>
              </p>
              <p>
                Two pairs: again, it is probably simplest to choose the ranks A, B, and C
                first. But here we have an overcounting problem, since there is symmetry in A
                and B. So there are <m>13\cdot 12 \cdot 11 / 2</m> many ways of choosing the three ranks
                A, B, and C, where the division by 2 represents the fact that 
                22JJA and JJ22A give the same choice.
                Once we have chosen the three ranks, we have <m>\binom42 \binom 42 \binom 41</m> many
                ways to choose cards of these ranks, so this is our total:
                <me>
                  \frac{ \frac{13\cdot 12 \cdot 11}{2} \cdot \binom42 \binom 42 \binom 41}{\binom{52}{5}}
                  \approx 0.0475.
                </me>
              </p>
            </solution>
          </example>
          <example>
            <title>Birthdays</title>
            <statement>
              <p>
                There are 28 students in the class. What is the probability that two of you chosen at random
                share a birthday?
              </p>
              <p>
                (You may make the simplifying assumptions that leap years don't exist 
                and that birthdays are uniformly distributed.)
              </p>
            </statement>
            <solution>
              <p>
                There are <m>365^{28}</m> possible outcomes, each of which is equally likely.
                This is a good example where <q>counting the complement</q> works well.
                That is, instead of counting the event we are asked to count, we will count its
                complement, the event that no two students share a birthday.
              </p>
              <p>
                The number of ways of assigning 28 distinct birthdays to 28 students is
                <m>\binom{365}{28} 28!</m>, the number of ways of choosing which 28 birthdays
                will be represented times the number of ways of assigning them to everyone in order.
                It may help to record another way of expressing this quantity:
                <me>
                  \binom{365}{28} 28! = 365 \cdot 364 \cdot \cdots \cdot 338.
                </me>
                Now we can simplify the probability that no two people share a birthday:
                <me>
                  P(\text{no birthday shared}) = \frac{\binom{365}{28} 28!}{365^{28}}
                  = \frac{365!}{337!} \cdot \frac{1}{365^{28}}.
                </me>
                A computer reports that this quantity is <m>\approx 0.3455</m>.
                So the probability that at least two people share a birthday is about <m>65\%</m>.
              </p>
            </solution>
          </example>
          <example xml:id="ex-matching-hats">
            <title>Matching hats</title>
            <statement>
              <p>
                Each of <m>n</m> people is wearing a hat that they toss into a pile.
                Then each person retrieves a hat at random. What is the probability that at least one
                person gets their hat back?
              </p>
            </statement>
            <solution>
              <p>
                Let <m>A_i</m> denote the event that the <m>i</m>th person gets their hat back.
                We want to compute <m>P(\bigcup_{1\le i \le n} A_i)</m>.
                Recall the Inclusion<ndash/>Exclusion Principle:
                <men xml:id="men-incl-excl">
                  P\left( \bigcup_{1\le i \le n} A_i \right)
                  = \sum_{i=1}^n P(A_i) - \sum_{i \lt j} P(A_i \cap A_j) + \sum_{i \lt j \lt k} P(A_i \cap A_j \cap A_k)
                    + \cdots + (-1)^{n+1} P(A_1 \cap \cdots \cap A_n)
                </men>
                Now <m>P(A_i) = \frac{1}{n}</m>; what about <m>P(A_i \cap A_j)</m>?
                Conditional probability gives us a nice way of thinking about this:
                <me>
                  P(A_i \cap A_j) = P(A_j) P(A_i | A_j) = \frac{1}{n} \cdot \frac{1}{(n-1)} = \frac{(n-2)!}{n!}.  
                </me>
                (Why? The probability that <m>i</m> gets their hat back given that <m>j</m> does is 
                <m>\frac{1}{n-1}</m>.)
                A similar argument shows that <m>P(A_i \cap A_j \cap A_k) = \frac{(n-3)!}{n!}</m>.
              </p>
              <p>
                Now we are in a position to simplify the expression in <xref ref="men-incl-excl"/>:
                <md>
                  <mrow> \amp = n \cdot \frac{1}{n} - \frac{(n-2)!}{n!} \binom{n}{2} + \frac{(n-3)!}{n!} \binom{n}{3} + \cdots </mrow>
                  <mrow> \amp = 1 - \frac{1}{2!} + \frac{1}{3!} - \cdots + \frac{(-1)^{n+1}}{n!}</mrow>
                </md>
                What we're really interested in is the behavior of this quantity as <m>n \to \infty</m>.
                Remembering a little calculus, we see that this probability converges to <m>1 - e^{-1} \approx 0.63</m>.
              </p>
            </solution>
          </example>
    </section>


    </chapter>

    <chapter xml:id="ch-random-variables">
      <title>Random variables</title>
      <section xml:id="sec-random-variables-theory">
      <title>Random variables: definition and examples</title>
      <subsection xml:id="subsec-random-variables">
        <title>Random variables: the basics</title>
        <p>
          Informally, a <term>random variable</term> is a random number 
          whose value is associated with the various outcome of an experiment.
        </p>
        <example>
          <p>
            Toss a fair coin three coins, so that the sample space <m>\Omega</m>
            includes outcomes like HHH, TTH, etc.
            One example of a random variable associated to this experiment is 
            simply the number <m>X</m> of heads.
          </p>
          <p>
            Here's a more sophisticated random variable.
            Suppose that we start with $1, double our money if we see heads
            and lose it all if we see tails.
            Then <m>W</m> could be our winnings after this experiment.
            (Notice that <m>W = 8</m> if we see HHH and <m>=0</m> otherwise.)
          </p>
        </example>
        <example>
          <p>
            Suppose that my neighbor and I each leave home independently between
            8 and 9am, each time equally likely, so <m>\Omega = [8,9]\times[8,9]</m>.
          </p>
          <p>
            One random variable is the time I leave: <m>(x,y) \mapsto x</m>.
            Another is the time between our departures: <m>(x,y) \mapsto |x - y|</m>.
          </p>
        </example>
        <p>
          Now we are ready for the formal definition.
          Suppose that <m>(\Omega, \mathcal{F}, P)</m> is a probability space.
        </p>
        <definition xml:id="def-random-var">
          <statement>
            <p>
              A <term>random variable</term> is a function <m>X\colon \Omega \to \R</m>
              satisfying the following technical assumption. For every <m>a\in \R</m>
              <me>
                \{ w\in \Omega : X(w) \le a \} \in \mathcal{F}.
              </me>
            </p>
          </statement>
        </definition>
        <remark>
          <p>
            We'll abbreviate e.g. <m>\{w\in \Omega : X(w) \le a \}</m> by
            <m>\{X \le a \}</m>.
          </p>
        </remark>
        <proposition xml:id="prop-rv-basic">
          <statement>
            <p>
              Let <m>X</m> be a random variable. 
              For all <m>a,b\in\R</m> the following are events (i.e., in <m>\mathcal{F}</m>).
              <ol marker="(i)">
                <li>
                  <p>
                    <m>\{X \gt a\}</m>
                  </p>
                </li>
                <li>
                  <p>
                    <m>\{X \lt a\}</m> and <m>\{X \ge a \}</m>
                  </p>
                </li>
                <li>
                  <p>
                    <m>\{a \lt X \lt b \}</m>, <m>\{a \le X \lt b \}</m>, etc.
                  </p>
                </li>
              </ol>
            </p>
          </statement>
          <proof>
            <p>
              <ol>
                <li>
                  <p>
                    <m>\{X \gt a\} = \{ X \le a \}^c</m> and <m>\mathcal{F}</m>
                    is closed under taking complements.
                  </p>
                </li>
                <li>
                  <p>
                    <m>\{X \lt a \} = \bigcup_{b\in\mathbb{Q}, \; b \lt a} \{X \le b\}</m>,
                    since <m>\mathbb{Q}</m> is order-dense in <m>\R</m>.
                    Since <m>\mathbb{Q}</m> is countable and each <m>\{X \le b\}</m> belongs to <m>\mathcal{F}</m>,
                    we can conclude that this countable union belongs to <m>\mathcal{F}</m> too.
                  </p>
                </li>
                <li>
                  <p>
                    Exercise.
                  </p>
                </li>
              </ol>
            </p>
          </proof>
        </proposition>
        <remark>
          <p>
            The set <m>\{X \in A\}</m> is an event for any <term>Borel set</term> <m>A\subseteq \R</m>.
            The Borel sets are the smallest <m>\sigma</m>-field containing all open sets.
          </p>
        </remark>
        <proposition xml:id="prop-rv-constructor">
          <statement>
            <p>
              If <m>X</m> and <m>Y</m> are random variables on <m>(\Omega,\mathcal{F}, P)</m> and <m>b\in\R</m>,
              then the following are all also random variables.
              <ol>
                <li>
                  <p>
                    <m>b X</m>
                  </p>
                </li>
                <li>
                  <p><m>X + Y</m></p>
                </li>
                <li><p><m>X \cdot Y</m></p></li>
                <li><p><m>
                  Z = \begin{cases} \frac{Y}{X} \amp \text{if } X \ne 0 \\
                  0 \amp \text{if } X = 0
                  \end {cases}
                </m></p></li>
              </ol>
            </p>
          </statement>
          <proof>
            <p>
              <ol>
                <li>
                  <p>
                    We need to show that <m>\{bX\le a\}</m> for every <m>a\in \R</m>,
                    but <m>\{X \le \tfrac{a}{b}\}\in \mathcal{F}</m> since <m>X</m> is a random
                    variable.
                  </p>
                  <p>
                    The rest are similar.
                  </p>
                </li>
              </ol>
            </p>
          </proof>
        </proposition>
        <definition xml:id="def-cdf">
          <statement>
            <p>
              Associated to a random variable <m>X</m> is a <term>cumulative distribution function</term>
              (cdf) <m>F\colon \R\to [0,1]</m> defined by <m>F(a) = P(X \le a)</m>.
            </p>
          </statement>
        </definition>
        <remark>
          <p>
            The definition of <q>random variable</q> ensures that <m>\{X\le a\}\in \mathcal{F}</m>,
            so <m>P(X\le a)</m> is defined.
          </p>
        </remark>
        <example>
          <statement>
            <p>
              Let <m>X</m> be the number of heads in three flips of a fair coin. 
              Describe its cdf.
            </p>
          </statement>
          <solution>
            <p>
              <me>
                F(a) = \begin {cases}
                  0 &amp;\text{if } a \lt 0 \\
                  \tfrac18 &amp; \text{if } 0 \le a \lt 1 \\
                  \tfrac12 &amp; \text{if } 1 \le a \lt 2 \\
                  \tfrac78 &amp; \text{if } 2 \le a \lt 3 \\
                  1 &amp; \text{if } 3 \le a
                \end {cases}
              </me> 
            </p>
            <image source="cdf-1.svg" width="80%"/>
          </solution>
        </example>
        <example>
          <statement>
            <p>
              My neighbor and I leave our houses again.
              Let <m>X</m> be the time I leave my house; this can be thought of as
              the projection <m>(x,y) \mapsto x</m>.
              Describe the cdf of <m>X</m>.
            </p>
          </statement>
          <solution>
            <p>
              <me>
                F(a) = \begin {cases}
                 0 \amp \text{if } a \lt 8 \\
                 a-8 \amp \text{if } 8 \le a \lt 9 \\
                 1 \amp \text{if } 9 \le a
                \end {cases}
              </me>
            </p>
            <image source="cdf-2" width="80%"/>
          </solution>
        </example>
        <proposition xml:id="prop-cdf-properties">
          <statement>
            <p>
              A cdf <m>F</m> for a rv <m>X</m> enjoys the following properties.
              <ol marker="(a)">
                <li>
                  <p>
                    <m>\lim\limits_{a\to-\infty} F(a) = 0</m> and <m>\lim\limits_{a\to\infty} F(a) = 1</m>
                  </p>
                </li>
                <li>
                  <p>
                    <m>F</m> is increasing: if <m>a \lt b</m> then <m>F(a) \le F(b)</m>.
                  </p>
                </li>
                <li>
                  <p>
                    <m>F</m> is <term>right-continuous</term>: <m>\lim\limits_{x\to a^+} F(x) = F(a)</m>
                  </p>
                </li>
                <li>
                  <p>
                    <m>P(X \gt a) = 1 - F(a)</m>
                  </p>
                </li>
                <li>
                  <p>
                    <m>P(a \lt X \le b) = F(b) - F(a)</m>
                  </p>
                </li>
                <li>
                  <p>
                    <m>P(X \lt a) = \lim\limits_{x\to a^-} F(x)</m>
                  </p>
                </li>
                <li xml:id="li-prob-jump">
                  <p>
                    <m>
                      P(X = a) = F(a) - \lim\limits_{x\to a^-} F(x)
                    </m>
                    (that is, <m>P(X = a)</m> is the <q>jump</q> that <m>F</m> makes at <m>a</m>)
                  </p>
                </li>
              </ol>
            </p>
          </statement>
        </proposition>
        <p>
          In fact, a function <m>F</m> satisfying the first three conditions
          of <xref ref="prop-cdf-properties"/> must in fact be realizable as the cdf
          of some random variable <m>X</m>, as you might have the pleasure of verifying
          on the homework.
        </p>
      </subsection>
      <subsection xml:id="subsec-discrete-rvs">
        <title>Discrete random variables</title>
        <definition xml:id="def-discrete-rv">
          <statement>
            <p>
              The random variable <m>X</m> is <term>discrete</term>
              if it takes values only in some countable subset
              <m>\{x_1,x_2,\dots\}</m> of <m>\R</m>.
              In this case we defined its <term>probability mass function (pmf)</term>
              <m>f\colon \R\to [0,1]</m> by
              <m>f(x) = P(X = x)</m>.
            </p>
          </statement>
        </definition>
        <p>
          Note that the nonzero values of the pmf
          <m>p_i = P(X = x_i)</m> satisfy <m>0 \le p_i \le 1</m>
          and <m>\sum_{1\le i} p_i = 1</m>.
          In particular, at least one <m>p_i</m> must be positive!
          We will contrast this below with the situation
          for <q>continuous</q> random variables.
        </p>
        <remark>
          <p>
            Most<mdash/>but not all!<mdash/>discrete random variables
            we consider will have <em>finite</em> range.
            But many interesting examples have (countably) infinite range;
            in this case the range will usually be something like <m>\mathbb{N}</m>.
          </p>
        </remark>
        <example>
          <p>
            A simple but important random variable is one that
            can take only two possible values, <m>0</m> and <m>1</m>.
            Such a random variable <m>X</m> is called a
            <term>Bernoulli random variable</term>, and we write
            <m>X \sim \Bernoulli(p)</m> where <m>p</m> denotes 
            <m>P(X = 1)</m>.
          </p>
          <p>
            Then <m>X</m> may represent the outcome of a biased coin
            or might be an <term>indicator rv</term> for some event <m>E</m>:
            <me>
              X(w) = 1_E(w) = \begin {cases}
              0 \amp w \in A^c \\
              1 \amp w \in A
              \end {cases}
            </me>
          </p>
          <p>
            The cdf <m>F</m> of a <m>\Bernoulli(p)</m> rv <m>X</m> is 
            described as follows.
            <me>
              F(x) = \begin {cases}
                0 \amp x \lt 0 \\
                1-p \amp 0 \le x \lt 1 \\
                1 \amp 1 \le x
              \end {cases}
            </me>
          </p>
        </example>
        <example>
          <p>
            Roll two dice, details to be added.
          </p>
        </example>
        <example>
          <p>
            Back to our usual example of tossing three coins,
            where <m>X</m> denotes the number of heads.
            Certainly <m>X</m> is discrete, since it has only four
            possible values: 0,1,2,3.
            This <m>X</m> has the following pmf.
            <me>
              f_X(x) = \begin {cases}
              \tfrac18 \amp x = 0,3 \\
              \tfrac38 \amp x = 1,2 \\
              0 \amp \text{otherwise}
              \end {cases}
            </me>
          </p>
        </example>
      </subsection>
        <subsection xml:id="subsec-cts-rvs">
          <title>Continuous random variables</title>
          <definition xml:id="def-cts-rv">
          <statement>
            <p>
              The rv <m>X</m> is <term>continuous</term> if its cdf
              <m>F</m> can be expressed as the integral of an integrable
              function <m>g</m> as follows.
              <me>
                F(x) = \int_{-\infty}^x g(u)\,du \quad \text{for all } x\in \R .
              </me>
              This (integrable) function <m>g</m> is called the 
              <term>probability density function (pdf)</term>
              of <m>X</m>.
            </p>
          </statement>
        </definition>
        <example>
          <p>
            Leaving home, to be added
          </p>
        </example>
        <remark>
          <p>
            <ol marker="(a)">
              <li>
                <p>
                  <m>X</m> is called <q>continuous</q>
                  since <m>F_X</m> is a continuous function.
                  Notice that this implies that <m>P(X = x) = 0</m>
                  for every <m>x\in \R</m>.
                  See <xref ref="li-prob-jump"/>.
                </p>
              </li>
              <li>
                <p>
                  By the Fundamental Theorem of Calculus,
                  <m>\frac{d}{dx}F(x) = g(x)</m> almost everywhere.
                </p>
              </li>
              <li>
                <p>
                  <m>P(X\in [a,b]) = F(b) - F(a) = \int_a^b g(u)\,du</m>.
                  In fact, <m>P(X\in B) = \int_B g(u)\,du</m> for any
                  Borel set <m>B</m>.
                  In particular, <m>\int_{-\infty}^\infty g(u)\,du = 1</m>.
                </p>
              </li>
              <li>
                <p>
                  In particular, for small <m>\epsilon</m>,
                  we have the following.
                  <me>
                    P(X \in [x,x+\epsilon]) = \int_x^{x+\epsilon} g(u)\,du \approx \epsilon g(x)
                  </me>
                  Dividing each side of this approximate equality by <m>\epsilon</m>,
                  we see that we are justified in calling <m>f</m> a <q>density</q> function.
                  Even though there is no <q>point-mass</q> at <m>x</m>,
                  there is density there.
                </p>
              </li>
            </ol>
          </p>
        </remark>
        <p>
          A continuous rv cannot be discrete, because a discrete rv
          must have point mass while a continuous rv cannot.
          But there are rvs that are neither continuous nor discrete.
        </p>
        <example>
          <statement>
            <p>
              Choose a real number from <m>\Omega = [-1,1]</m>, each equally likely.
              If it is negative, round it up to 0. Otherwise leave it alone.
              Let <m>X</m> be the result of this procedure. 
              Show that <m>X</m> is neither discrete nor continuous.
            </p>
          </statement>
          <solution>
            <p>
              Then <m>X</m> cannot be continuous, for <m>P(X = 0) = 1/2</m>.
              But <m>X</m> can take any value in <m>[0,1]</m>, of which
              there are uncountably many. So <m>X</m> is not discrete, either.
            </p>
          </solution>
        </example>
      </subsection>
      </section>
      <section xml:id="sec-discrete-rvs">
        <title>Discrete random variables</title>
        <introduction>
        <example>
          <statement>
            <p>
              We perform <m>n</m> independent trials, each with a fixed probability
              <m>p</m> of success. 
              The total number of successes at the end is a <term>binomial random variable</term>
              with parameters <m>n</m> and <m>p</m>; we write <m>X \sim \binomial(n,p)</m>.
              Find its probability mass function.  
            </p>
          </statement>
          <solution>
            <p>
              Fix <m>k \le n</m>. There are <m>\binom nk</m>-many ways of choosing which of the 
              <m>k</m> trials will end in success. Then the probability that these <m>k</m> trials
              succeed and the other <m>n-k</m> fail is (by independence) <m>p^k (1-p)^{n-k}</m>.
              Multiplying these gives the value <m>p(k)</m> of the pmf at <m>k</m>:
              <me>
                p(k) = \binom nk p^k (1-p)^{n-k}
              </me>
              You can view a graph of this pmf at 
              <url href="https://www.geogebra.org/calculator/ykvdawbt" visual="geogebra.org">this GeoGebra link</url>.
            </p>
            <p>
              Later we will make precise the guess that the <q>center of mass</q>
              of this pmf occurs at <m>p n</m>.
            </p>
          </solution>
        </example>
        <exercise>
          <p>
            Verify that <m>\sum_{0\le k \le n} p(k) = 1</m>.
          </p>
        </exercise>
        <definition xml:id="def-indep-rv">
          <statement>
            <p>
              Two random variables <m>X</m> and <m>Y</m> on the same probability
              space are <term>independent</term> if for all <m>x,y\in\R</m>
              the events <m>\{X \le x\}</m> and <m>\{Y \le y\}</m> are independent.
            </p>
            <p>
              If <m>X</m> and <m>Y</m> are discrete, then it is equivalent to 
              require that for all <m>x,y\in\R</m> the events <m>\{X = x\}</m>
              and <m>\{Y = y\}</m> are independent.
            </p>
          </statement>
        </definition>
        <p>
          Then a random variable is <m>\binomial(n,p)</m> if and only if
          it is a sum of <m>n</m> independent <m>\Bernoulli(p)</m> random variables:
          <me>
            Y = X_1 + \cdots + X_n
          </me>
        </p>
        <example>
          <statement>
          <p>
            Independent trials are performed, each with a fixed probability
            <m>p</m> of success. The number of trials required to see the first
            success is a <term>geometric</term> random variable with parameter
            <m>p</m>, and if it's called <m>X</m> then we write
            <m>X \sim \geometric(p)</m>.
            Compute the pmf of a <m>\geometric(p)</m> random variable.
          </p>
        </statement>
        <solution>
          <p>
            The possible values of <m>X</m> are <m>1,2,3,\dots</m>.
            Fix a positive integer <m>k</m>.
            The probability that the first <m>k-1</m> trials fail
            and the <m>k</m>th succeeds is 
            <me>
              f(k) = (1-p)^{k-1} p
            </me>
          </p>
        </solution>
        </example>
        <exercise>
          <p>
            Verify for the pmf <m>f</m> of a <m>\geometric(p)</m> 
            random variable that
            <me>
              \sum_{1 \le k} f(k) = 1.
            </me>
          </p>
        </exercise>
      </introduction>
        <subsection xml:id="subsec-expectation-discrete">
          <title>The expectation of a discrete random variable</title>
          <definition xml:id="def-expectation-discrete">
            <statement>
              <p>
                The <term>expected value</term>, <term>expectation</term>,
                or <term>mean</term> of a discrete random variable <m>X</m>
                with pmf <m>f</m> is defined as follows.
                <me>
                  E(X) = \sum_{x} xf(x) = \sum_i x_i p_i,
                </me>
                whenever this sum converges absolutely.
                (Otherwise the expected value does not exist.)
              </p>
            </statement>
          </definition>
          <exercise>
            <p>
              Verify that this agrees with the gradeschool notion of mean
              in the case <m>p_1 = p_2 = \cdots = p_n = \tfrac1n</m>.
            </p>
          </exercise>
          <example>
            <p>
              A <m>\Bernoulli(p)</m> random variable has mean <m>p</m>:
              <me>
                \sum_x x f(x) = 0\cdot f(0) + 1 \cdot f(1) = 0(1-p) + p = p.
              </me>
            </p>
            <p>
              In particular, <m>E(1_A) = P(A)</m>.
            </p>
          </example>
          <example>
            <p>
              In order to compute the expectation of <m>Y \sim \binomial(n,p)</m>,
              we must make sense of the following quantity.
              <me>
                E(Y) = \sum_{k=0}^n k \binom nk p^k (1-p)^{n-k}
              </me>
              After some thought, we might notice that this is the following
              function of <m>x</m> and <m>y</m> evaluated at <m>x = p</m>,
              <m>y = 1-p</m>.
              <md>
                <mrow> \sum_{k=0}^n k \binom nk x^k y^{n-k}
                \amp = x \frac{d}{dx} \sum_{k=0}^n \binom nk x^k y^{n-k} </mrow>
                <mrow> \amp = x \frac{d}{dx} (x+y)^{n} </mrow>
                <mrow> \amp = x n (x+y)^{n-1}  </mrow>
              </md>
              (We have used the Binomial Theorem.)
              Now, plugging in <m>x = p</m> and <m>y = 1-p</m> gives
              <me>
                pn(p + 1-p)^{n-1} = pn.
              </me>
              But this is much easier using the linearity of expectation!
            </p>
          </example>
          <theorem xml:id="thm-linearity-expectation-discrete">
            <statement>
              <p>
                The expectation operator <m>E</m> is linear; that is,
                <md>
                  <mrow> E(aX) \amp = a E(X) </mrow>
                  <mrow> \text{and} \quad E(X+Y) \amp = E(X) + E(Y) </mrow>
                </md>
              </p>
            </statement>
            <proof>
              <p>
                It is useful to notice that, for fixed <m>x\in\R</m>,
                <m>\{X = x\} = \bigcup_y \{X = x \text{ and } Y = y\}</m>,
                and that this is a disjoint union.
                Thus, by the additivity of the probability measure,
                <m>P(X = x) = \sum_y P(X = x \text{ and } Y = y)</m>.
                We will use this fact and a similar one with the roles of 
                <m>X</m> and <m>Y</m> interchanged in what follows.
              </p>
              <p>
                <md>
                  <mrow> E(X+Y) \amp = \sum_z zP(X+Y = z)</mrow>
                  <mrow> \amp = \sum_x \sum_y (x+y) P(X = x \text{ and } Y = y) </mrow>
                  <mrow> \amp = \sum_x x \left[ \sum_y P(X = x \text{ and } Y = y) \right] 
                    + \sum_y y \left[ \sum_x P(X = x \text{ and } Y = y) \right]
                  </mrow>
                  <mrow>
                    \amp = \sum_x x P(X = x) + \sum_y y P(Y = y)
                  </mrow>
                  <mrow> \amp = E(X) + E(Y)</mrow>
                </md>
                The proof that <m>E(aX) = aE(X)</m> is easier and is left as an exercise.
              </p>
            </proof>
          </theorem>
          <example>
            <p>
              Now it is much easier to compute the expectation of a binomial
              random variable: if <m>Y \sim \binomial(n,p)</m> then there are 
              independent <m>\Bernoulli(p)</m> random variables <m>X_1,\dots,X_n</m>
              of which <m>Y</m> is the sum, and now we can use the linearity of expectation:
              <me>
                E(Y) = E(X_1) + \cdots + E(X_n) = np.
              </me>
            </p>
          </example>
          <lemma xml:id="lem-lotus">
            <statement>
              <p>
                Suppose that <m>X</m> is a discrete random variable with pmf <m>f</m>
                and that <m>g\colon\R\to\R</m> is any function. Then the expectation
                of the random variable <m>g(X)</m> can be computed as follows.
                <me>
                  E(g(X)) = \sum_x g(x) f(x).
                </me>
              </p>
            </statement>
            <proof>
              <p>
                Exercise.
              </p>
            </proof>
          </lemma>
          <definition xml:id="def-moments">
            <statement>
              <p>
                Let <m>X</m> be a random variable.
                For <m>k\in\N</m> we define the <m>k</m>th <term>moment</term> of <m>X</m>,
                denoted <m>m_k(X)</m>, to be <m>E(X^k)</m>.
                The <m>k</m>th <term>central moment</term> of <m>X</m>, denoted
                <m>\sigma_k(X)</m>, to be <m>E((X- E(X))^k)</m>.
              </p>
              <p>
                Of particular note is <m>\sigma_2 = E((X - E(X))^2) = \var(X)</m>,
                the <term>variance</term> of <m>X</m>.
              </p>
            </statement>
          </definition>
          <p>
            The variance of <m>X</m> measures the tendency of <m>X</m>
            to deviate from its mean.
          </p>
          <exercise>
            <p>
              Show that <m>\var(X) = E(X^2) - E(X)^2</m>.
            </p>
          </exercise>
          <example>
            <statement>
              <p>
                Compute the variance of a <m>\Bernoulli(p)</m> random variable.
              </p>
            </statement>
            <solution>
              <p>
                We see that 
                <me>
                  E(X^2) = \sum_x x^2 f(x) = 0^2 (1-p) + 1^2 p = p,
                </me>
                so the variance is given by
                <me>
                  \var(X) = E(X^2) - E(X)^2 = p - p^2 = p(1-p).
                </me>
              </p>
            </solution>
          </example>
          <example>
            <title>Matching, revisited</title>
            <statement>
            <p>
              Recall <xref ref="ex-matching-hats"/>, in which we determined
              that, when <m>n</m> people's hats are randomly shuffled,
              the probability that at least one person gets their hat back
              is 
              <me>
                1 - \frac{1}{2!} + \frac{1}{3!} - \cdots + \frac{(-1)^{n+1}}{n!},
              </me>
              a quantity that tends as <m>n\to\infty</m> to <m>1 - \tfrac1e</m>.
            </p>
            <p>
              Now, letting <m>X</m> be the number of people who receive
              their own hat, find <m>E(X)</m> and <m>\var(X)</m>.
            </p>
          </statement>
          <solution>
            <p>
              Consider, for <m>k=1,\dots,n</m>, the following indicator random variable.
              <me>
                I_k = \begin {cases}
                1 \amp \text{ if the } k \text{th person gets his hat back} \\
                0 \amp \text{ otherwise}
                \end {cases}
              </me>
              Notice that <m>E(I_k)</m> equals the probability that the <m>k</m>th
              person gets their hat back, which as we discovered in the previous
              example is <m>\tfrac1n</m>. Now we use the linearity of expectation:
              <me>
                E(X) 
                = E\left( \sum_{k=1}^n I_k \right)
                = \sum_{k=1}^n E(X_k) = \sum_{k=1}^n \frac1n = 1.
              </me>
            </p>
            <p>
              <md>
                <mrow> E(X^2) \amp = E \left[ \left( \sum_{k=1}^n I_k \right)^2 \right]</mrow>
                <mrow> \amp = E \left[ \sum_{k=1}^n I_k^2 + \sum_{j\ne k} I_j I_k \right]</mrow>
                <mrow> \amp = \sum_{k=1}^n E[I_k^2] + \sum_{j \ne k} E[I_j I_k]</mrow>
                <mrow> \amp = \sum_{k=1}^n \frac{1}{n} + \sum_{j\ne k} \frac{1}{n(n-1)} </mrow>
                <mrow> \amp = 1 + n(n-1)\frac{1}{n(n-1)}</mrow>
                <mrow> \amp = 2</mrow>
              </md>
              For that we needed to compute <m>E[I_j I_k]</m>:
              <md>
                <mrow> E(I_j I_k) \amp = 1P(\text{both } j \text{ and } k \text{ get their hat back}) + 0P(\text{at least one doesn't}) </mrow>
                <mrow> \amp = 1\cdot \frac{1}{n(n-1)} + 0 </mrow>
              </md>
              Now we can conclude that
              <me>
                \var(X) = E(X^2) - E(X)^2 = 2 - 1 = 1.
              </me>
            </p>
          </solution>
          </example>
          <example>
            <title>Coupon Collector</title>
            <statement>
              <p>
                A fast-food restaurant offers kiddie meals that each include
                a toy. There are <m>N</m> different toys available, and toys
                are equally likely to be in a given meal.
                <ol marker="(a)">
                 <li>
                  <p>
                    Find the expected number of meals needed to collect all the toys.
                  </p>
                 </li>
                 <li><p>Find the expected number of different toys collected
                  if <m>M</m> kiddie meals are purchased.
                 </p></li>
                </ol>
              </p>
            </statement>
            <solution>
              <p>
                Let <m>X</m> be the number of meals before all <m>N</m> toys are collected.
                Then <m>X = X_0 + X_1 + \cdots + X_{N-1}</m>,
                where <m>X_k</m> is the number of additional meals after <m>k</m>
                different toys have collected to get another toy.
                By linearity of expectation, <m>E(X) = \sum_{k=0}^{N-1} E(X_k)</m>.
                Notice that <m>X_k \sim \geometric\left(\frac{N-k}{N}\right)</m>,
                since after <m>k</m> different toys have been collected,
                the chance of any particular meal giving us a new toy is <m>\frac{N-k}{N}</m>.
              </p>
              <p>
                Recalling that a <m>\geometric(p)</m> random variable has expectation <m>\tfrac1p</m>,
                we are now in position to compute the expectation of <m>X</m>.
                <md>
                  <mrow> E(X) \amp = \sum_{k=0}^{N-1} E(X_k) </mrow>
                  <mrow> \amp = 1 + \frac{N}{N-1} + \frac{N}{N-2} + \cdots + N</mrow>
                  <mrow> \amp = N\left( \frac{1}{N} + \frac{1}{N-1} + \cdots + 1\right) </mrow>
                  <mrow> \amp = N H(N) ,</mrow>
                </md>
                where <m>H(N)</m> is the <m>N</m>th <term>harmonic number</term>.
                This quantity for <m>N=6</m> is approximately <m>15</m>
                and for <m>N = 8</m> is approximately <m>22</m>.
              </p>
              <p>
                For part (b), let <m>X</m> be the number of different toys
                collected if <m>M</m> kiddie meals are purchased,
                and let <m>Y = N - X</m> be the number of toys missing from the 
                collection after <m>M</m> meals. 
                Then <m>Y</m> can be written as a sum
                <me>
                  Y = Y_1 + \cdots + Y_N,
                </me>
                where
                <me>
                  Y_k = \begin {cases} 0 \amp \text{ if the } k \text{th toy is in the collection} \\
                  1 \amp \text{ if it's missing}
                  \end {cases}
                </me>
                Note that <m>E(Y_k) = 1p+0(1-p) = p</m>,
                where <m>p</m> is the probability that we didn't get the <m>k</m>th
                toy in <m>M</m> meals, which is <m>\left( \frac{N-1}{N}\right)^M</m>.
                Now <m>E(Y) = \sum_{k=1}^N E(Y_k) = N\left(1-\frac{1}{N}\right)^M</m>.
                And we can compute the expected value of <m>X</m>:
                <me>
                  E(X) = N - E(Y) = N - N\left(1 - \frac{1}{N}\right)^M
                </me>
                Notice that this quantity approaches <m>N</m> as <m>M\to\infty</m>,
                as expected.
              </p>
            </solution>
          </example>
        </subsection>
        <subsection xml:id="subsec-poisson">
          <title>The Poisson Distribution</title>
          <p>
            Consider <m>X \sim \binomial(n,p)</m> and let <m>n\to\infty</m>
            and <m>p\to 0</m> while fixing <m>\lambda = np</m>:
            <md>
              <mrow> \binom nk p^k (1-p)^{n-k} \amp = \binom nk \left( \frac{\lambda}{n} \right)^k \left( 1 - \frac{\lambda}{n}\right)^{n-k} </mrow>
              <mrow> \amp = \frac{n(n-1)(n-2)\cdots(n-k+1)}{k!} \cdot \frac{\lambda^k}{n^k}\left( 1 - \frac{\lambda}{n}\right)^n \left( 1 - \frac{\lambda}{n}\right)^{-k}</mrow>
              <mrow> \amp = \frac{n(n-1)(n-2)\cdots(n-k+1)}{n^k} \cdot \frac{\lambda^k}{k!}\left( 1 - \frac{\lambda}{n}\right)^n \left( 1 - \frac{\lambda}{n}\right)^{-k}</mrow>
              <mrow> \amp \underset{n\to\infty}{\longrightarrow} 1 \cdot \frac{\lambda^k}{k!} \cdot e^{-\lambda} \cdot 1
                = \frac{\lambda^k}{k!} e^{-\lambda} </mrow>
            </md>
          </p>
          <definition xml:id="def-poisson">
            <statement>
              <p>
                A random variable is said to follow a <term>Poisson</term> distribution
                with parameter <m>\lambda\in (0,\infty)</m> if its pmf <m>f</m> is given by
                <me>
                  f(k) = \frac{\lambda^k}{k!} e^{-\lambda}
                </me>
              </p>
            </statement>
          </definition>
          <p>
            A <m>\Poisson(\lambda)</m> random variable is a good model for
            a rare event that occurs on average <m>\lambda</m> times per unit time.
          </p>
          <exercise>
            <p>
              Verify that <m>\sum_{k\ge 0} \frac{\lambda^k}{k!} e^{-\lambda} = 1</m>.
            </p>
          </exercise>
          <example>
            <statement>
              <p>
                Compute the expected value of a <m>\Poisson(\lambda)</m>
                random variable.
              </p>
            </statement>
            <solution>
              <p>
                <md>
                  <mrow> E(X) \amp = \sum_{k\ge 0} k f(k) </mrow>
                  <mrow> \amp = \sum_{k\ge 0} k \frac{\lambda^k}{k!} e^{-\lambda} </mrow>
                  <mrow> \amp = \lambda e^{-\lambda} \sum_{k\ge 1} \frac{\lambda^{k-1}}{(k-1)!}</mrow>
                  <mrow> \amp = \lambda e^{-\lambda} \sum_{m\ge0} \frac{\lambda^m}{m!} </mrow>
                  <mrow> \amp = \lambda e^{-\lambda} e^{\lambda} </mrow>
                  <mrow> \amp = \lambda </mrow>
                </md>
              </p>
            </solution>
          </example>
          <exercise>
            <p>
              Show that <m>\var(X) = \lambda</m> too.
            </p>
          </exercise>
          <example>
            <statement>
              <p>
                Astronomers estimate that on average one large meteorite
                hits Earth every 100 years. Compute the probability that 
                no large meteorite hits Earth in the next 100 years.
              </p>
            </statement>
            <solution>
              <p>
                We model the number of meteorites coming in the next century by a 
                <m>\Poisson(1)</m> random variable.
                The probability that no meteorite comes in the next century
                is <m>\frac{1e^{-1}}{0!} = \frac{1}{e} \approx 0.37</m>.
                This means there is a <m>63\%</m> chance that at least one meteorite
                will hit in the next 100 years.
              </p>
            </solution>
          </example>
          <example>
            <statement>
              <p>
                Our observations indicate that on average <m>1</m> gram of 
                radioactive material discharges <m>3.2</m> ɑ particles per second.
                Compute the probability that at most two ɑ particles will appear.
              </p>
            </statement>
            <solution>
              <p>
                <md>
                  <mrow> P(E) \amp = f(0) + f(1) + f(2) </mrow>
                  <mrow> \amp = e^{-3.2} + 3.2 e^{-3.2} + \frac{3.2^2}{2!}e^{-3.2} </mrow>
                  <mrow> \amp \approx 0.3799 </mrow>
                </md>
                So approximately a <m>38\%</m> chance.
              </p>
            </solution>
          </example>
          <example>
            <title>Poisson Coin Flips</title>
            <statement>
              <p>
                Suppose that a coin with probability <m>p</m> of showing heads
                is tossed <m>N</m> times. Let <m>X</m> be the number of heads
                and <m>Y</m> the number of tails.
                Then <m>X</m> and <m>Y</m> are certainly not independent;
                from the value of one we can compute the value of the other!
              </p>
              <p>
                Nonetheless, show that if we toss the coin a <em>random</em>
                number <m>N \sim \Poisson(\lambda)</m> of times,
                then <m>X</m> and <m>Y</m> are independent!
              </p>
            </statement>
            <solution>
              <p>
                We must show for all <m>k,l</m> that the events
                <m>\{X = k\}</m> and <m>\{Y = l\}</m> are independent,
                i.e., that
                <me>
                  P(X = k \text{ and } Y = l) = P(X = k) P(Y = l).
                </me>
                Start with the lefthand side:
                <md>
                  <mrow> P(X = k \text{ and } Y = l) \amp = P(X = k \text{ and } Y = l \mid N = k+l)P(N = k+l) </mrow>
                  <mrow> \amp = \binom{k+l}{l} p^k (1-p)^l \frac{\lambda^{k+l}}{(k+l)!} e^{-\lambda} </mrow>
                  <mrow> \amp = \frac{(k+l)!}{k! l!} p^k (1-p)^l \frac{\lambda^{k+l}}{(k+l)!} e^{-\lambda} </mrow>
                  <mrow> \amp = \frac{ (p\lambda)^k ((1-p)\lambda)^l}{k! l! } e^{-\lambda}</mrow>
                </md>
                Toward the righthand side, start by using the Law of Total Probability:
                <md>
                  <mrow> P(X = k) \amp = \sum_{n \ge k} P(X = k \mid N = n) P(N = n) </mrow>
                  <mrow> \amp = \sum_{n\ge k} \binom nk p^k (1-p)^{n-k} \frac{\lambda^n}{n!} e^{-\lambda} </mrow>
                  <mrow> \amp = \frac{p^k e^{-\lambda}}{k!} \lambda^k \sum_{n \ge k} \frac{(1-p)^{n-k}}{(n-k)!} \lambda^{n-k} </mrow>
                  <mrow> \amp = \frac{p^k e^{-\lambda}}{k!} \lambda^k \sum_{m \ge 0} \frac{(1-p)^m}{m!} \lambda^m </mrow>
                  <mrow> \amp = \frac{(\lambda p)^k e^{-\lambda p}}{k!} </mrow>
                </md>
                Similarly,
                <me>
                  P(Y = l) = \frac{ (\lambda(1-p))^l e^{-\lambda(1-p)}}{l !}
                </me>
                Combining all this, we get:
                <me>
                  P(X = k)P(Y = l) = \frac{(\lambda p)^k (\lambda(1-p))^l e^{-\lambda}}{ k! l!} = P(X = k \text{ and } Y = l)
                </me>
              </p>
            </solution>
          </example>
        </subsection>
        <subsection xml:id="subsec-discrete-more-examples">
          <title>More examples of discrete distributions</title>
          <definition xml:id="def-neg-binom">
            <statement>
              <p>
                Independent <m>\Bernoulli(p)</m> trials are performed until
                a total of <m>r</m> successes are achieved.
                Let <m>X</m> be the number of trials required.
                Notice that the pmf of <m>X</m> is given by the following formula.
                <me>
                  P(X = n) = \binom{n-1}{r-1} p^r (1-p)^{n-r}, \qquad n=r,r+1,\dots
                </me>
                (The <m>n</m>th trial must be a success; there are <m>\binom{n-1}{r-1}</m>
                many ways to choose which of the remaining trials succeed; then the chance
                that the trials that are supposed to succeed do succeed and the others
                fail is <m>p^r (1-p)^{n-r}</m>.)
              </p>
              <p>
                A random variable with this pmf is said to follow 
                a <term>negative binomial</term> distribution with parameters
                <m>r</m> and <m>p</m>; we write <m>X \sim \NegBinom(r,p)</m>.
              </p>
            </statement>
          </definition>
        </subsection>
        <subsection xml:id="subsec-variance-correlation">
          <title>Correlation and variance</title>
          <p>
            Recall that <m>\var(X)</m> is defined to be <m>E((X-E(X))^2)</m>
            and is equal to <m>E(X^2) - E(X)^2</m>.
            We should not expect this statistic to be linear, since as we will verify
            we expect <m>\var(aX) = a^2 \var(X)</m>.
            But it is natural to wonder under what conditions it is <em>additive</em>,
            meaning <m>\var(X+Y) = \var(X) + \var(Y)</m>.
          </p>
          <definition xml:id="def-uncorrelated">
            <statement>
              <p>
                Two random variables <m>X</m> and <m>Y</m> are <term>uncorrelated</term>
                if <m>E(XY) = E(X)E(Y)</m>.
              </p>
            </statement>
          </definition>
          <lemma xml:id="lem-independent-uncorrelated">
            <statement>
              <p>
                If <m>X</m> and <m>Y</m> are independent, then they are
                uncorrelated.
              </p>
            </statement>
            <proof>
              <p>
                <md>
                  <mrow> E(XY) \amp = \sum_{x,y} xy P(X = x \text{ and } Y = y) </mrow>
                  <mrow> \amp = \sum_{x,y} xy P(X = x) P(Y = y) </mrow>
                  <mrow> \amp = \sum_{x} x P(X = x) \sum_y y P(Y = y) </mrow>
                  <mrow> \amp = E(X) E(Y) </mrow>
                </md>
              </p>
            </proof>
          </lemma>
          <p>
            The converse is false!
          </p>
          <example>
            <statement>
              <p>
                Let <m>X</m> and <m>Y</m> be independent Bernoulli random variables
                with parameter <m>1/2</m>. 
                Show that <m>X+Y</m> and <m>\abs{X-Y}</m> are dependent but uncorrelated.
              </p>
            </statement>
            <solution>
              <p>
                To show that <m>X+Y</m> and <m>\abs{X-Y}</m> are dependent,
                it is enough to show that the events <m>\{X+Y = 0\}</m>
                and <m>\{\abs{X-Y} = 0\}</m> are dependent.
                But of course! The only way for <m>X+Y</m> to equal <m>0</m>
                is for <m>X = Y = 0</m>, and this implies that <m>\abs{X-Y} = 0</m>.
                In other words, <m>P(X+Y = 0 \text{ and } \abs{X-Y} = 0) = 
                  P(X+Y = 0) = \tfrac14</m> and <m>P(\abs{X-Y}=0) = \tfrac12</m>,
                  and <m>\tfrac14 \cdot \tfrac12 \ne \tfrac14</m>.
              </p>
              <p>
                To see that <m>X+Y</m> and <m>\abs{X-Y}</m> are uncorrelated,
                we compute all the relevant expected values by hand:
                <me>
                  E(X+Y) = E(X) + E(Y) = \tfrac12 + \tfrac12 = 1.
                </me>
                <me>
                  E(\abs{X-Y}) = 0P(\abs{X-Y}=0) + 1P(\abs{X-Y} = 1) = \tfrac12
                </me>
                <me>
                  E(\abs{X-Y}(X+Y)) = 0P(Z = 0) + 1P(Z = 1) + 2P(Z = 2)
                  = 1P(\abs{X-Y}(X+Y)=1) = \tfrac12
                </me>
                And <m>\tfrac12 \cdot 1 = \tfrac12</m>, so <m>X+Y</m> and <m>\abs{X-Y}</m>
                are uncorrelated.
              </p>
            </solution>
          </example>
          <p>
            And here is the reason for making the definition:
          </p>
          <proposition xml:id="prop-variance-uncorrelated">
            <statement>
              <p>
                <ol marker="(a)">
                  <li>
                    <p>
                      <m>\var(aX) = a^2 \var(X)</m>
                    </p>
                  </li>
                  <li>
                    <p>
                      If <m>X</m> and <m>Y</m> are uncorrelated,
                      then <m>\var(X+Y) = \var(X) + \var(Y)</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
            <proof>
              <p>
                The first part follows immediately from the definition of 
                variance and the linearity of expectation:
                <me>
                  \var(aX) = E((aX - E(aX)^2))
                  = E(a^2 (X - E(X))^2)
                  = a^2 \var(X)
                </me>
              </p>
              <p>
                The second part follows from our other characterization of variance:
                <md>
                  <mrow> \var(X+Y) \amp = E((X+Y)^2) - (E(X+Y))^2 </mrow>
                  <mrow> \amp = E(X^2 + 2XY + Y^2) - E(X)^2 - 2E(X)E(Y) - E(Y)^2 </mrow>
                  <mrow> \amp = E(X^2) + 2E(XY) + E(Y^2) - E(X)^2 - 2E(X)E(Y) - E(Y)^2 </mrow>
                  <mrow> \amp = \var(X) + \var(Y) </mrow>
                </md>
                That's it.
              </p>
            </proof>
          </proposition>
          <example>
            <p>
              A <m>\binomial(n,p)</m> random variable <m>X</m> can be expressed
              as a sum <m>X = X_1 + \cdots + X_n</m> of independent <m>\Bernoulli(p)</m>
              random variables. Recall that the variance of a <m>\Bernoulli(p)</m>
              random variable is <m>p(1-p)</m>.
              Since the <m>X_k</m> are independent, they are uncorrelated.
              So <m>\var(X) = \sum_{k=1}^n p(1-p) = np(1-p)</m>.
            </p>
          </example>
        </subsection>
      </section>
      <section xml:id="sec-cts-rvs">
        <title>Continuous random variables</title>
        <introduction>
        <p>
          Now we develop the theory of continuous random variables in much the same
          way as we did for the discrete case.
        </p>
        <definition xml:id="def-expectation-cts">
          <statement>
            <p>
              The <term>expected value</term> or <term>expectation</term>
              of a continuous random variable <m>X</m> with pdf <m>f</m>
              is defined as the following integral, when it converges.
              <me>
                E(X) = \int_{-\infty}^\infty xf(x)\,dx
              </me>
            </p>
          </statement>
        </definition>
      </introduction>
        <subsection xml:id="subsec-exponential">
          <title>The exponential distribution</title>
          <p>
            to be added
          </p>
        </subsection>
        <subsection xml:id="subsec-gaussian">
          <title>The Gaussian distribution</title>
          <p>
            to be added
          </p>
        </subsection>
      </section>
      <section xml:id="sec-some-inequalities">
        <title>Some Inequalities</title>
      <p>How likely is a random variable to deviate greatly from its mean?</p>
      <theorem xml:id="thm-chebyshev">
        <title>Chebyshev's Inequality</title>
        <statement>
          <p>
            Let <m>X</m> be a random variable and <m>a \gt 0</m>. Then
            <me>
              P( |X| \ge a) \le \frac{E(X^2)}{a^2}.
            </me>
          </p>
          <p>
            In particular, when <m>\mu = E(X) = 0</m> and <m>\var(X) = \sigma^2</m>, we have
            <me>
              P(|X| \ge a) \le \frac{\sigma^2}{a^2}.
            </me>
            So <m>X</m> must concentrate around its mean in a way that's bounded by its variance.
          </p>
        </statement>
      </theorem>
      <example>
        <p>
          For <m>a = k \sigma</m>, we have
          <me>
            P(X \text{ is more than } k \text{ standard deviations from its mean}) \le \frac{1}{k^2}.
          </me>
          This is valid <em>regardless</em> of the distribution of <m>X</m>
        </p>
      </example>
      <p>
        So Chebyshev is very general; it needs only the first two moments of <m>X</m>.
        But there is a trade-off: in specific cases it can give a poor estimate.
      </p>
      <example>
        <p>
          Suppose <m>X \sim \gauss(0,1)</m>. We can compute <m>P(|X| \ge k)</m> by direct computation:
          <md>
            <mrow>P(|X| \ge k) \amp = 2 \frac{1}{\sqrt{2\pi}} \int_k^\infty e^{-x^2/2}\,dx </mrow>
            <mrow> \amp \le \sqrt{\frac2\pi} \int_k^\infty \frac{x}{k} e^{-x^2}{2}\,dx </mrow>
            <mrow> \amp = \cdots = \frac{2}{k\sqrt\pi} e^{-k^2}{2} </mrow>
          </md>
          This is <em>much</em> smaller than <m>\frac{1}{k^2}</m>, the bound given by Chebyshev.
        </p>
      </example>
      <p>
        Soon we'll prove Chebyshev's Inequality, but it will be easier to first prove another inequality.
      </p>
      <theorem xml:id="thm-markov">
        <title>Markov's Inequality</title>     
        <statement>
          <p>
            Let <m>X \ge 0</m> be a random variable and <m>a \gt 0</m> be a constant. Then
            <me>
              P(X \ge a) \le \frac{E(X)}{a}.
            </me>
          </p>
        </statement>
        <proof>
          <p>Put <m>A = \{X \ge a\}</m>. Since <m>X \ge 0</m>, we have <m>X \ge a 1_A</m>. (Check this, perhaps by considering 
          separately the cases <m>X \le a</m> and <m>X \gt a</m>.)
         Take the expectation of each side:
         <me>
          E(X) \ge E(a1_A) = a P(A).
         </me>
         Rearrange to get what we want.
        </p>
        </proof>
      </theorem>
      <p>
        Note that Markov's Inequality applies even when <m>\var(X)</m> isn't finite (or is unknown),
        unlike Chebyshev's.
      </p>
      
      <proof>
        <title>Proof of <xref ref="thm-chebyshev"/></title>
        <p>
          Apply Markov's Inequality to <m>b = a^2</m> and <m>Y = X^2</m> to get
          <me>
            P(X^2 \ge a^2) = P(Y \ge b) \le \frac{E(Y)}{b} = \frac{E(X^2)}{a^2}.
          </me>
          Notice that <m>X^2 \ge a^2</m> iff <m>|X| \ge a</m>, so we have Chebyshev's Inequality.
        </p>
      </proof>

      <example>
        <statement>
          <p>
            A factory produces an average of 50 items per day.
            <ol>
              <li>
                <p>
                  Comment on the probability that today's production exceeds 75 items.
                </p>
              </li>
              <li>
                <p>
                  If the standard deviation is 5 items per day, what can be said about the probability
                  that today's production level will be between 40 and 60 items?
                </p>
              </li>
            </ol>
          </p>
        </statement>
        <solution>
          <p>
            <ol>
              <li>
                <p>
                  By Markov, <m>P(X \ge 75) \le \frac{E(X)}{75} = \frac{50}{75} = \frac23</m>.
                </p>
              </li>
              <li>
                <p>
                  Apply Chebyshev to <m>X - 50</m>, which has the same variance as <m>X</m> but mean 0:
                  <me>
                    P( |X - 50| \ge 10) \le \frac{E(X^2)}{10^2} = \frac{25}{100} = \frac14.
                  </me>
                </p>
              </li>
            </ol>
          </p>
        </solution>
      </example>

      </section>
    </chapter>

    <chapter xml:id="ch-joint-distributions">
      <title>Jointly distributed random variables</title>
      <section>
        <title>Definitions and examples</title>
        <p>
        If <m>X</m> and <m>Y</m> are random variables on the same probability
        space, then their cdfs <m>F_X</m> and <m>F_Y</m> tell us about
        how they are distributed, individually. But with only this 
        information, we don't know how they act relative to each other.
      </p>
      <example>
        <p>
          <alert>Situation A.</alert>
          Flip two coins and define
          <me>
            X = \begin {cases} 1 \amp \text{1st is heads} \\
            0 \amp \text{otherwise}
            \end{cases}
            \qquad
            Y = \begin {cases} 1 \amp \text{2nd is heads} \\
            0 \amp \text{otherwise}
            \end {cases} .
          </me>
          Then <m>X</m> and <m>Y</m> are identically distributed;
          they both follow a <m>\Bernoulli(1/2)</m> distribution
          and therefore have the same pmf and cdf.
        </p>
        <p>
          <alert>Situation B.</alert>
          Now flip only one coin and consider <m>X = 1_H</m> and <m>Y = 1_T</m>.
          (That is, <m>X</m> is the indicator rv of the event that the result
          is a heads, and <m>Y</m> indicates whether the result is a tails.)
          Then <m>X</m> and <m>Y</m> are identically distributed <m>\Bernoulli(1/2)</m>
          random variables, just as in Situation A.
        </p>
        <p>
          But clearly these two situations are different!
          How do we capture that?
          It might occur to us to record <term>joint probabilies</term>
          in a 2D array:
          <me>
            A: \begin {array} {c | cc}
             X / Y \amp 0 \amp 1 \\\hline
             0 \amp 1/4 \amp 1/4  \\
            1 \amp 1/4 \amp 1/4
            \end {array}
            \qquad 
            B: \begin {array} {c | cc}
             X / Y \amp 0 \amp 1 \\\hline
             0 \amp 0 \amp 1/2  \\
            1 \amp 1/2 \amp 0
            \end {array}
          </me>
        </p>
      </example>
      <definition xml:id="def-jmf">
        <statement>
          <p>
            The <term>joint mass function</term> of discrete random
            variables <m>X</m> and <m>Y</m> is defined by
            <me>
              f_{X,Y}(x,y) = P(X = x \text{ and } Y = y).
            </me>
          </p>
        </statement>
      </definition>
      <remark>
        <p>
          <ol>
            <li>
                Discrete random variables <m>X</m> and <m>Y</m>
                are independent if and only if their joint mass function
                is the pointwise product of their mass functions:
                <me>
                  f_{X,Y}(x,y) = f_X(x) f_Y(y) \quad \forall x,y
                </me>
                (This holds in Situation A of the example but not
                in Situation B.)
            </li>
            <li>The definition of <term>joint mass function</term>
            can be extended to more than two random variables.
          We probably won't worry about that much, though.</li>
          <li>
            <p>
            <m>f_X(x) = \sum_y f(x,y)</m> and <m>f_Y(y) = \sum_x f(x,y)</m>.
          Follows from the Law of Total Probability.
        Thus, we get the so-called <term>marginal mass functions</term> by 
      taking sums down columns and rows in the joint mass function tables:
      <me>
        A: \begin {array} {c | cc | c}
         X / Y \amp 0 \amp 1 \amp f_X \\\hline
         0 \amp 1/4 \amp 1/4 \amp 1/2 \\
        1 \amp 1/4 \amp 1/4 \amp 1/2 \\\hline
        f_Y \amp 1/2 \amp 1/2 \amp 
        \end {array}
        \qquad 
        B: \begin {array} {c | cc | c}
         X / Y \amp 0 \amp 1 \amp f_X \\\hline
         0 \amp 0 \amp 1/2 \amp 1/2 \\
        1 \amp 1/2 \amp 0 \amp 1/2 \\\hline
        f_Y \amp 1/2 \amp 1/2 \amp
        \end {array}
      </me>
    </p></li>
          </ol>
        </p>
      </remark>
      <p>
        In Situation A, <m>X</m> and <m>Y</m> are uncorrelated.
        In Situation B, they are correlated. By how much?
      </p>
      <definition xml:id="def-cov">
        <statement>
          <p>
            The <term>covariance</term> of random variables <m>X</m> and 
            <m>Y</m> is defined by
            <me>
              \cov(X,Y) = E((X - EX)(Y - EY)).
            </me>
            The <term>correlation coefficient</term>
            of <m>X</m> and <m>Y</m> is
            <me>
              \rho(X,Y) = \frac{ \cov(X,Y)}{\sqrt{\var(X)}\sqrt{\var(Y)}},
            </me>
            provided <m>\var(X)</m> and <m>\var(Y)</m> are both nonzero.
          </p>
        </statement>
      </definition>
      <remark>
        <p>
          Some properties:
          <ol>
            <li>
              <m>\cov(X,X) = \var(X)</m>
            </li>
            <li>
              Recall that <m>\var(X) = E(X\cdot X) - E(X)E(X)</m>.
              In a moment we will prove that
              <m>
                \cov(X,Y) = E(XY) - E(X)E(Y).
              </m>
            </li>
            <li><m>\cov(X,Y) = 0</m> iff <m>X</m> and <m>Y</m> are uncorrelated.
            This follows immediately from the previous item.</li>
            <li>
              <m>\abs{\rho(X,Y)} \le 1</m>.
              (This will also be proved soon.)
            </li>
          </ol>
        </p>
      </remark>
<lemma xml:id="lem-cov-formula">
  <statement>
    <p>
      For all random variables <m>X</m> and <m>Y</m>, we have 
      <me>
        \cov(X,Y) = E(XY) - E(X)E(Y).
      </me>
    </p>
  </statement>
  <proof>
    <p>
      Essentially the same proof we gave for the case <m>X = Y</m>.
      Just expand and use linearity of expectation:
      <md>
        <mrow> \cov(X,Y) \amp = E(XY - YE(X) - XE(Y) + E(X)E(Y)) </mrow>
        <mrow> \amp = E(XY) - E(X)E(Y) - E(X)E(Y) + E(X)E(Y) </mrow>
        <mrow> \amp = E(XY) - E(X)E(Y) </mrow>
      </md>
    </p>
  </proof>
</lemma>
<example>
  <p>
    Back to our example with Situations A and B.
    In Situation A we have <m>\cov(X,Y) = 0</m> since <m>X</m> and 
    <m>Y</m> are independent therefore uncorrelated.

    In Situation B, we have:
    <me>
      \cov(X,Y) = E(XY) - E(X)E(Y) = 0 - \frac14 = -\frac14.
    </me>
    So <m>X</m> and <m>Y</m> are <term>negatively correlated</term>,
    meaning when <m>X</m> decreases then <m>Y</m> increases, and vice versa.
    More specifically,
    <me>
      \rho(X,Y) = \frac{-1/4}{\sqrt{1/4 \cdot 1/4}} = -1,
    </me>
    which (as we will show) is as negative as possible.
    So <m>X</m> and <m>Y</m> in this example are as negatively correlated
    as possible.
  </p>
</example>
<example>
  <p>
    Suppose that <m>1_A</m> and <m>1_B</m> are indicator random variables
    for events <m>A</m> and <m>B</m>. We have the following:
    <me>
      E(1_A) = P(A), \quad E(1_B) = P(B), \quad E(1_A 1_B) = P(A \cap B).
    </me>
    So the covariance of <m>1_A</m> and <m>1_B</m> is given by
    <me>
      \cov(1_A,1_B) = P(A \cap B) - P(A) P(B) = P(B)( P(A \mid B) - P(A)).
    </me>
    This means that <m>1_A</m> and <m>1_B</m> are ...
    <md>
      <mrow> \text{positively correlated} \amp \text{ iff } P(A \mid B) \gt P(A) ;</mrow>
      <mrow> \text{negatively correlated} \amp \text{ iff } P(A \mid B) \lt P(A)  ;\text { and} </mrow>
<mrow> \text{uncorrelated} \amp \text{ iff } P(A \mid B) = P(A). </mrow>
    </md>
  </p>
</example>
<example>
  <statement>
    <p>
      Flip a fair coin three times.
      Let <m>X</m> count the number of heads in the first 2 flips.
      Let <m>Y</m> count the number of heads in the last 2 flips.
      Compute <m>\cov(X,Y)</m>.
    </p>
  </statement>
  <solution>
    <p>
      It might be informative to solve this directly from the definition,
      even though we have the convenient formula of <xref ref="lem-cov-formula"/>.
      Notice that <m>E(X) = E(Y) = 1</m>.
      Look at the joint mass function:
      <me>
        \begin {array} {c | ccc | c}
         X / Y \amp 0 \amp 1 \amp 2 \amp f_X \\\hline
         0 \amp 1/8 \amp 1/8 \amp 0 \amp 1/4 \\
        1 \amp 1/8 \amp 1/4 \amp 1/8 \amp 1/2 \\
        2 \amp 0 \amp 1/8 \amp 1/8 \amp 1/4 \\\hline
        f_Y \amp 1/4 \amp 1/2 \amp 1/4 \amp 
        \end {array}
      </me>
      and compute the covariance directly from the definition:
      <md>
        <mrow> \cov(X,Y) \amp = E((X-EX)(Y-EY)) </mrow>
        <mrow> \amp = \sum_{i,j} f_{X,Y}(x_i,y_j)(x_i-1)(y_j-1) </mrow>
        <mrow> \amp = \frac18(0-1)(0-1) + \frac18(2-1)(2-1) = \frac14</mrow>
      </md>
    </p>
    <p>
      It is easier (and in more complicated examples this will be truer)
      to use the formula, though:
      <me>
        E(XY) = 1\frac28 + 2\frac18 + 2\frac18 + 4\frac18 = \frac54,
      </me>
      so
      <me>
        \cov(X,Y) = E(XY) - E(X)E(Y) = \frac54 - 1 = \frac14.
      </me>
    </p>
  </solution>
</example>
</section>
    </chapter>

    <chapter xml:id="ch-generating-fns-limit-thms">
      <title>Generating Functions and Limit Theorems</title>
      <section xml:id="sec-pgfs">
        <title>Probability generating functions</title>
        <p>
          What is a pgf?
        </p>
      </section>
      <section xml:id="sec-characteristic-fns">
        <title>Characteristic functions</title>
        <definition xml:id="def-char-fn">
          <statement>
            <p>
              The <term>characteristic function</term> of a random variable <m>X</m> is the function
              <m>\phi_X \colon \R\to\C</m> given by <m>\phi_X(t) = E(e^{itX})</m>.
            </p>
            <p>
              When <m>X</m> is discrete with values in <m>\N</m>, this is
              <m>\phi_X(t) = G_X(e^{it})</m>.
              When <m>X</m> is continuous with density function <m>f_X</m>, this is
              <m>\phi_X(t) = \int_\R e^{itx} f_X(x)\,dx</m>, the <term>Fourier Transform</term>
              of <m>f_X</m>.
            </p>
          </statement>
        </definition>
        <p>
          The characteristic function looks like just a mild modification of the mgf,
          but adding the <m>i</m> to the exponent makes a big difference:
          recall that for a real number <m>t</m>, <m>\abs{e^{it}} = 1</m>.
        </p>
        <remark>
          <p>
            Wait, how do we even make sense of <xref ref="def-char-fn"/>?
            The quantity <m>e^{itX}</m> is not (typically) a real number!
            We're considering <em>complex-valued</em> random variables now.
            A function <m>Y \colon \Omega \to \C</m> is a <term>complex-valued random variable</term>
            if both <m>\Re(Y) \colon \Omega \to \R</m> and <m>\Im(Y) \colon\Omega \to \R</m> are 
            random variables, so that <m>Y = \Re(Y) + i \Im(y)</m>.
          </p>
          <p>
            In the definition, we are considering <m>Y = e^{itX} = \cos(tX) + i \sin(tX)</m>;
            both <m>\cos(tX) = \Re(Y)</m> and <m>\sin(tX) = \Im(Y)</m> are random variables by 
            standard closure properties of random variables.
            (This is really just jointly distributed random variables repackaged in a complex-numbers
            format.)
            Then the expectation of <m>Y</m> is defined to be 
            <m>E(Y) = E(\Re(Y)) + iE(\Im(Y))</m>.
          </p>
        </remark>
        <lemma xml:id="lem-char-fn-basic">
          <statement>
            <p>
              Suppose that <m>X</m> is a random variable with characteristic function <m>\phi = \phi_X</m>.
              <ol marker="(a)">
                <li>
                  <p>
                    <m>\phi(0) = 1</m>, and <m>\abs{\phi(t)} \le 1</m> for all <m>t\in\R</m>.
                  </p>
                </li>
                <li>
                  <p>
                    <m>\phi</m> is uniformly continuous on <m>\R</m>.
                  </p>
                </li>
              </ol>
            </p>
          </statement>
          <proof>
            <p>
              <m>\phi(0) = E(e^0) = 1</m>.
              We'll prove the second part of (a) for continuous <m>X</m>; the discrete case is similar.
              <md>
                <mrow> \abs{\phi(t)} \amp = \abs{E(e^{itx})} = \abs{\int_\R e^{itx} f_X(x)\,dx}</mrow>
                <mrow> \amp \le \int_\R \abs{f_X(x)} \abs{e^{itx}}\,dx</mrow>
                <mrow> \amp \le \int_\R \abs{f_X(x)}\,dx = 1 </mrow>
              </md>
            </p>
            <p>
              Part (b) requires some analysis. Fix <m>t</m> and <m>h</m>. We must show that <m>\abs{\phi(t+h) - \phi(t)} \to 0</m>
              as <m>h \to 0</m> in a way that is independent of <m>t</m>.
              <md>
                <mrow> \abs{\phi(t+h) - \phi(t)} \amp = \abs{E(e^{itx}(e^{ihx} - 1))} </mrow>
                <mrow> \amp = \abs{\int_\R e^{itx} (e^{ihx} - 1) f_X(x) \,dx }</mrow>
                <mrow> \amp \le \int_\R \abs{e^{ihx} - 1} f_X(x)\,dx </mrow>
                <mrow> \amp \underset{h\to 0}{\longrightarrow} 0 </mrow>
              </md>
              (To justify the last line, argue that the integrand is bounded by <m>2f_X(x)</m>
              and <m>e^{ihx} - 1 \to 0</m> and apply the Dominated Convergence Theorem.)
            </p>
          </proof>
        </lemma>
        <example>
          <statement>
            <p>
              Find the characteristic functions of these random variables.
              <ol marker="(a)">
                <li>
                  <p>constant r.v. <m>X = a</m> .</p>
                </li>
                <li><p>
                  <m>X \sim \bernoulli(p)</m>
                </p></li>
                <li><p>
                  <m>X \in \{-1,+1\}</m> with <m>P(X = -1) = P(X = 1) = 1/2</m>.
                </p></li>
                <li><p>
                  <m>X \sim\binomial(n,p)</m>
                </p></li>
                <li><p>
                  <m>X \sim \poisson(\lambda)</m>
                </p></li>
                <li><p>
                  <m>X \sim \exponential(\lambda)</m>
                </p></li>
              </ol>
            </p>
          </statement>
          <solution>
            <p>
              The discrete examples (all but the last one) can be computed using the identity
              <m>\phi_X(t) = G_X(e^{it})</m> and our work on pgfs:
              <ol marker="(a)">
                <li>
                  <p>
                    <m>\phi_X(t) = e^{iat}</m>, which traverses the unit circle at speed <m>\abs{a}</m>,
                    either CW or CCW depending on the sign of <m>a</m>.
                  </p>
                </li>
                <li><p>
                  <m>X \sim \bernoulli(p)</m>: <m>\phi_X(t) = pe^{it} + 1-p</m>, 
                  which traverses the circle of radius <m>p</m> centered at <m>1-p</m>.
                </p></li>
                <li><p>
                  <m>X \in \{-1,+1\}</m> with <m>P(X = -1) = P(X = 1) = 1/2</m>.
                  <m>\phi_X(t) = \frac12 e^{it} + \frac12 e^{-it} = \cos(t)</m>.
                </p></li>
                <li><p>
                  <m>X \sim\binomial(n,p)</m>:
                  <m>\phi_X(t) = (pe^{it} + 1-p)^n</m> by a fact that we're about to prove
                  or by our work on pgfs.
                </p></li>
                <li><p>
                  <m>X \sim \poisson(\lambda)</m>:
                  <m>\phi_X(t) = G_X(e^{it}) = e^{\lambda(e^{it} - 1)}</m>.
                </p></li>
                <li><p>
                  <m>X \sim \exponential(\lambda)</m>:
                  <md>
                    <mrow> \phi_X(t) \amp = \int_0^\infty \lambda e^{-\lambda x} e^{itx} \,dx </mrow>
                    <mrow> \amp = \lambda \int_{x=0}^\infty e^{x(it - \lambda)}\,dx</mrow>
                    <mrow> \amp = \lambda \left[ \frac{e^{x(it - \lambda)}{it - \lambda}} \right]_{x=0}^\infty </mrow>
                    <mrow> \amp = \frac{\lambda}{\lambda - it} </mrow>
                  </md>
                </p></li>
              </ol>
            </p>
          </solution>
        </example>
        <example>
          <title>The characteristic function of a normal rv</title>
          <p>
            Suppose that <m>X \sim \gauss(0,1)</m>, so that the density of <m>X</m> is given by
            <m>f_X(t) = \frac{1}{\sqrt{2\pi}} e^{-t^2/2}</m>. First, we just apply the definition:
            <me>
              \phi_X(t) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} e^{itx} e^{-x^2/2} \,dx 
              = \int_{-\infty}^\infty e^{itx - x^2/2}\,dx .
            </me>
            Now we do something non-obvious:
            for a real number <m>a\in \R</m> we have the following.
            <md>
              <mrow> \frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty e^{ax - x^2/2}\,dx 
                \amp = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty e^{a^2/2} e^{-(x-a)^2/2} \,dx </mrow>
              <mrow> \amp = e^{a^2/2} \frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty e^{-(x-a)^2/2} \,dx </mrow>
              <mrow> \amp = e^{a^2/2} \frac{1}{\sqrt{2\pi}} \int_{u=-\infty}^\infty e^{-u^2/2} \,du </mrow>
              <mrow> \amp = e^{a^2/2} </mrow>
            </md>
            We have shown that the functions
            <me>
              \frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty e^{ax - x^2/2}\,dx \quad\text{and}\quad e^{a^2/2}
            </me>
            of a complex variable <m>a\in\C</m> agree for all <m>a\in\R</m>.
            Both of these functions are analytic, so they must agree for all <m>a\in\C</m>,
            in particular for all <m>a = it</m>, <m>t\in\R</m>. Thus,
            <me>
              \phi_X(t) = e^{(it)^2/2} = e^{-t^2/2}.
            </me>
          </p>
          <p>
            The fact that the density function of a <m>\gauss(0,1)</m> random variable is an eigenfunction
            of the Fourier Transform is in some sense why the Central Limit Theorem is true.
          </p>
        </example>
        <exercise>
          <p>
            Show that the characteristic function of <m>X \sim \gauss(\mu,\sigma^2)</m>
            is given by <m>\phi_X(t) = e^{i\mu t - (\sigma t)^2/2}</m>.
          </p>
        </exercise>
        <lemma xml:id="lem-char-fn-props">
          <title>Properties of characteristic functions</title>
          <statement>
            <p>
              what needs to go here?
            </p>
          </statement>
        </lemma>
        
      </section>
    </chapter>
    <backmatter xml:id="backmatter">
      <title>Backmatter</title>

      <colophon>
        <p> This book was authored in <pretext />. </p>
      </colophon>

    </backmatter>

  </book>
</pretext>
